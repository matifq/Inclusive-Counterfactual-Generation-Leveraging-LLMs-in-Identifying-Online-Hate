{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69020a82-bee0-406b-b594-9f3d8ac9da5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install advertools --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53dda71-9eb2-497d-a555-1cfce4d1a11e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import config\n",
    "gpt_response_file = config.gpt_response_lshs_file\n",
    "gpt_filtered_rephrase_tweets_file = config.gpt_filtered_rephrase_lshs_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e29dfa-1d5b-4334-998c-8cc49510d425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_file = open(gpt_response_file, \"r\")\n",
    "gtp_dict = json.load(out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276de86b-08e6-4398-9917-6a0b3ed76298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "# The default levels are DEBUG, INFO, WARNING, ERROR, and CRITICAL.\n",
    "print(logging.WARNING)\n",
    "logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc34265-93f3-4302-a8e2-fadeaf76f40b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validateJSON(jsonData):\n",
    "    try:\n",
    "        json.loads(jsonData)\n",
    "    except Exception as e:\n",
    "        return False, e\n",
    "    return True, None\n",
    "\n",
    "def prepare_json(s, e, k):\n",
    "    if (s[0] == '{' and s[1:].find('{')>-1):\n",
    "        return fix_json(s, k)\n",
    "    else:\n",
    "        return convert_to_json(s, k)\n",
    "\n",
    "def convert_to_json(text, k):\n",
    "    logging.debug(\"not a json \" + str(k))\n",
    "    return text, 1\n",
    "    \n",
    "def get_line_and_col(input_string):\n",
    "    # input_string = \"Expecting ',' delimiter: line 3 column 56 (char 66)\"\n",
    "\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'line (\\d+) column (\\d+) \\(char \\d+\\)'  # Matches the line and column numbers\n",
    "\n",
    "    # Use the search method to find the first match of the pattern in the string\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    # Extract the line and column numbers from the match\n",
    "    if match:\n",
    "        line_number = int(match.group(1))\n",
    "        column_number = int(match.group(2))\n",
    "        return line_number, column_number\n",
    "    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfacd037-c6b9-4077-8228-7b4222c7ece5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 20:17:04 INFO     Total Fixed:330\n",
      "2023-06-11 20:17:04 INFO     Total Broken:1805\n",
      "2023-06-11 20:17:04 INFO     Total Entries: 10790\n",
      "2023-06-11 20:17:04 INFO     Total Recovered Entries: 8985\n",
      "2023-06-11 20:17:04 INFO     Percentage of Total Valid: 83.27%\n"
     ]
    }
   ],
   "source": [
    "def extra_comma_before_list_or_dict_closes(fixed_json):\n",
    "    pre_fixed_json = fixed_json\n",
    "    fixed_json = re.sub(r'(,\\s+)(]|})', r'\\2', fixed_json, flags=re.DOTALL)\n",
    "    if not pre_fixed_json == fixed_json:\n",
    "        logging.debug('> extra_comma_before_list_or_dict_closes fixed')\n",
    "        # print(fixed_json)\n",
    "    return fixed_json\n",
    "\n",
    "def missing_comma(fixed_json):\n",
    "    pre_fixed_json = fixed_json\n",
    "    fixed_json = re.sub(r'(\"])(\\s+)(\")', r'\\1,\\2\\3', fixed_json, flags=re.DOTALL)\n",
    "    if not pre_fixed_json == fixed_json:\n",
    "        logging.debug('> missing common issue fixed')\n",
    "        # print(fixed_json)\n",
    "    return fixed_json\n",
    "\n",
    "def fix_string_replace_single_quote_with_double(fixed_json):\n",
    "    pre_fixed_json = fixed_json\n",
    "    fixed_json = re.sub(r\"(')(.+?)(')(\\s*)(,|]|})\", r'\"\\2\"\\4\\5', fixed_json)\n",
    "    if not pre_fixed_json == fixed_json:\n",
    "        logging.debug('> fix_string_replace_single_quote_with_double')\n",
    "        # print(fixed_json)\n",
    "    return fixed_json\n",
    "\n",
    "def add_quotation_around_key(fixed_json):\n",
    "    # Fix the key without quotattions by adding \"{key}\"\n",
    "    pre_fixed_json = fixed_json\n",
    "    # ((,|{)[\\t\\n\\r\\s]+)([a-zA-Z0-9_ ]+)(\\s*:) --> group 1 and 2 repeats\n",
    "    fixed_json = re.sub(r'(,|{)([\\t\\n\\r\\s]+)([a-zA-Z0-9_ ]+)(\\s*:)', r'\\1\\2\"\\3\"\\4', fixed_json, flags=re.DOTALL)\n",
    "    \n",
    "    if not pre_fixed_json == fixed_json:\n",
    "        logging.debug('> key quotes issue fixed')\n",
    "        # print(fixed_json)\n",
    "    return fixed_json\n",
    "\n",
    "def replace_consecutive_commas(fixed_json):\n",
    "    #replace consecutive commas\n",
    "    pre_fixed_json = fixed_json\n",
    "    fixed_json = re.sub(r'(,)([\\s\\t\\n])*(,)+', r'\\1', fixed_json, flags=re.DOTALL) \n",
    "    if not pre_fixed_json == fixed_json:\n",
    "        logging.debug('> consecutive_commas issue fixed')\n",
    "        # print(fixed_json)\n",
    "    return fixed_json\n",
    "\n",
    "\n",
    "def fix_single_slash(fixed_json):\n",
    "    #replace consecutive commas\n",
    "    pre_fixed_json = fixed_json\n",
    "    fixed_json = re.sub(r'(\\w|\\s)(\\\\)(\\s+)', r'\\1\\2\\2\\3', fixed_json, flags=re.DOTALL) \n",
    "    if not pre_fixed_json == fixed_json:\n",
    "        logging.debug('> single_slash issue fixed')\n",
    "        # print(fixed_json)\n",
    "    return fixed_json\n",
    "\n",
    "def fix_square_brackets(fixed_json):\n",
    "    pre_fixed_json = fixed_json\n",
    "    # Fix the string data by adding square brackets around the \"Problematic terms\" values\n",
    "    if not (re.search('(\"P|p)(roblematic)( |_)([\\w\\(\\)]+\":\\s*)(\\[)', fixed_json)): # bracket open is not found in the list\n",
    "        # print('here1')\n",
    "        \n",
    "        fixed_json = re.sub(r'(\"P|p|R|r)(roblematic|ephrased)( |_)([\\w\\(\\)]+\":)[\\s-]*(.*?)\\s*((}|\\s)*(,\\n)|(}|\\s)(}|\"[\\w\\s]+\":))', r'\\1\\2\\3\\4[\\5]\\6', fixed_json, flags=re.DOTALL)  # missing bracket \"problematic_terms\": \"aa\", \"bb\", (}) 975, 12900, 15940\n",
    "        # fixed_json = re.sub(r'(\"P|p)(roblematic)( |_)([\\w\\(\\)]+\":\\s*)(.*?)\\s*((}|\\s)*(,\\n)|(}|\\s)(}))', r'\\1\\2\\3\\4[\\5]\\6', fixed_json, flags=re.DOTALL)  # missing bracket \"problematic_terms\": \"aa\", \"bb\", (}) 975, 12900\n",
    "        # fixed_json = re.sub(r'(\"P|p)(roblematic)( |_)([\\w\\(\\)]+\":\\s*)(.*?)\\s*(}|\\s)*(,\\n)', r'\\1\\2\\3\\4[\\5]\\6\\7', fixed_json, flags=re.DOTALL)  # missing bracket \"problematic_terms\": \"aa\", \"bb\", \n",
    "    # if not (re.search('(\"P|p)(roblematic)( |_)([\\w\\(\\)]+\":\\s*)(\\[)', fixed_json)): # bracket open is not found in the list\n",
    "    #     print('here2')\n",
    "    #     fixed_json = re.sub(r'(\"P|p)(roblematic)( |_)([\\w\\(\\)]+\":\\s*)(.*?)\\s*(}|\\s)(})', r'\\1\\2\\3\\4[\\5]\\6\\7', fixed_json, flags=re.DOTALL)  # missing bracket \"problematic_terms\": \"aa\", \"bb\",(}) \n",
    "    ##     fixed_json = re.sub(r'(\"P|p)(roblematic)( |_)([\\w\\(\\)]+\":\\s*)(.*?)\\s*(\\n})', r'\\1\\2\\3\\4[\\5]\\6', fixed_json, flags=re.DOTALL)  # missing bracket \"problematic_terms\": \"aa\", \"bb\"}\n",
    "    \n",
    "    fixed_json = re.sub(r'(\")(,])(\\s+)(\")', r'\\1],\\3\\4', fixed_json, flags=re.DOTALL)  # fix sitation forced by inserting bracket or may exist as error in json too\n",
    "    \n",
    "    fixed_json = re.sub(r'(\")(\\s*-\\s*)(\")', r'\\1 , \\3', fixed_json, flags=re.DOTALL) # list seperated by -\n",
    "    \n",
    "    if not pre_fixed_json == fixed_json:\n",
    "        logging.debug('> square bracket issue fixed')\n",
    "        # print(fixed_json)\n",
    "    return fixed_json\n",
    "\n",
    "def fix_escape_seq(fixed_json, k, max_iter=50):\n",
    "    isValid = validateJSON(fixed_json)\n",
    "    e = isValid[1]\n",
    "    # print(k, e)\n",
    "    for it in range(0, max_iter): # 50 errors to fix\n",
    "        fixed=False\n",
    "        e = str(e)\n",
    "        l, c = get_line_and_col(e)\n",
    "        # print(l,c)\n",
    "        lines = fixed_json.split('\\n')\n",
    "        # print(lines[l-1])\n",
    "        # print('-->', lines[l-1][c-3:c])\n",
    "        bugs_fix = {'\"': '\\\\\"', ',': '\",'}\n",
    "        for i in range(min(len(lines[l-1])-1, c-2), max(0, c-4), -1):\n",
    "            # print('-->', i, len(lines[l-1]))\n",
    "            ch = lines[l-1][i]\n",
    "            # print('--->', ch)\n",
    "            if ch in bugs_fix:\n",
    "                # print('yes')\n",
    "                # print('<<', lines[l-1][:i] + bugs_fix[ch] + lines[l-1][i+1:])\n",
    "                lines[l-1] = lines[l-1][:i] + bugs_fix[ch] + lines[l-1][i+1:]\n",
    "                # print(lines[l-1])\n",
    "                fixed = True\n",
    "                break\n",
    "        if not fixed:\n",
    "            break\n",
    "        fixed_json = '\\n'.join(lines)\n",
    "        \n",
    "        isValid = validateJSON(fixed_json)\n",
    "        if isValid[0]:\n",
    "            logging.debug(\"Fixed \" + str(k))\n",
    "            return fixed_json, 0\n",
    "        e = isValid[1]\n",
    "        # print('loop')\n",
    "    # Print the fixed JSON string\n",
    "    logging.debug('Not fixed ' + str(k))\n",
    "    # print(fixed_json)\n",
    "    return fixed_json, 1\n",
    "    \n",
    "def fix_json(invalid_json, k):\n",
    "    fixed_json = invalid_json\n",
    "    \n",
    "    function_list = [add_quotation_around_key,\n",
    "                     replace_consecutive_commas, fix_square_brackets,\n",
    "                     extra_comma_before_list_or_dict_closes, fix_single_slash, missing_comma,\n",
    "                     fix_string_replace_single_quote_with_double                    \n",
    "                    ]\n",
    "    \n",
    "    for func in function_list:\n",
    "        fixed_json = func(fixed_json)\n",
    "        isValid = validateJSON(fixed_json)\n",
    "        if isValid[0]:\n",
    "            logging.debug(\"Fixed \" + str(k))\n",
    "            return fixed_json, 0\n",
    "        \n",
    "    return fix_escape_seq(fixed_json, k)\n",
    "    \n",
    "\n",
    "def fix_bad_json():\n",
    "    valid_tweets = {}\n",
    "    cnt_broken = 0\n",
    "    cnt_fixed = 0\n",
    "    for k, v in gtp_dict.items():\n",
    "        # too bad --> 9000 re behaviour is strange\n",
    "        if int(k) in [9000, 9795, 13145, 13795, 14605]:\n",
    "            cnt_broken += 1\n",
    "            continue\n",
    "        # if int(k)==14605 :\n",
    "            # s=v\n",
    "            # print(v)\n",
    "            # fixed_json = v\n",
    "        #     fix_square_brackets\n",
    "        #    fixed_json = fix_square_brackets(fixed_json)\n",
    "            # fixed_json = extra_comma_before_list_or_dict_closes(fixed_json)\n",
    "            # print(fixed_json)\n",
    "            # fixed_json = fix_string_replace_single_quote_with_double(fixed_json)\n",
    "            # fixed_json, _ = fix_escape_seq(fixed_json, k)\n",
    "        #     fix_escape_seq\n",
    "            # print(fixed_json)\n",
    "            # print(validateJSON(fixed_json))\n",
    "            # break\n",
    "        # else:\n",
    "        #     continue\n",
    "        isValid = validateJSON(v)\n",
    "        if not isValid[0]:\n",
    "            # d, c = prepare_json(v, isValid[1], k)\n",
    "            try:\n",
    "                # print(k)\n",
    "                v, c = prepare_json(v, isValid[1], k)\n",
    "                if c == 0:\n",
    "                    cnt_fixed += 1\n",
    "                else:\n",
    "                    cnt_broken += 1\n",
    "                    continue\n",
    "                # json.loads(d)\n",
    "            except Exception as e:\n",
    "                # cnt_broken+= 1\n",
    "                print('not fixable', k, e)\n",
    "                if (str(e).find(\"Expecting\")>-1):\n",
    "\n",
    "                    pass\n",
    "                continue\n",
    "        \n",
    "        valid_tweets[k] = v\n",
    "    logging.info('Total Fixed:' + str(cnt_fixed*5))\n",
    "    logging.info('Total Broken:' + str(cnt_broken*5))\n",
    "    logging.info('Total Entries: ' + str(len(gtp_dict.keys())*5))\n",
    "    logging.info('Total Recovered Entries: ' + str(len(valid_tweets.keys())*5))\n",
    "    p = str(round((len(valid_tweets.keys())*5)/(len(gtp_dict.keys())*5)*100, 2)) +'%'\n",
    "    logging.info('Percentage of Total Valid: ' + p)\n",
    "    return valid_tweets\n",
    "    \n",
    "\n",
    "\n",
    "valid_tweets = fix_bad_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354f8f2a-293b-46b7-a0c8-f6c8ea2b4468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 150 to 155\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 335 to 340\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 370 to 375\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 510 to 515\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 630\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 631\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 632\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 633\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 634\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 650 to 655\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['765_original_tweet', '765_rephrased_tweets', '765_suspected_problematic_terms', '766_original_tweet', '766_rephrased_tweets', '766_suspected_problematic_terms', '767_original_tweet', '767_rephrased_tweets', '767_suspected_problematic_terms', '768_original_tweet', '768_rephrased_tweets', '768_suspected_problematic_terms', '769_original_tweet', '769_rephrased_tweets', '769_suspected_problematic_terms'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['765_original_tweet', '765_rephrased_tweets', '765_suspected_problematic_terms', '766_original_tweet', '766_rephrased_tweets', '766_suspected_problematic_terms', '767_original_tweet', '767_rephrased_tweets', '767_suspected_problematic_terms', '768_original_tweet', '768_rephrased_tweets', '768_suspected_problematic_terms', '769_original_tweet', '769_rephrased_tweets', '769_suspected_problematic_terms'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['765_original_tweet', '765_rephrased_tweets', '765_suspected_problematic_terms', '766_original_tweet', '766_rephrased_tweets', '766_suspected_problematic_terms', '767_original_tweet', '767_rephrased_tweets', '767_suspected_problematic_terms', '768_original_tweet', '768_rephrased_tweets', '768_suspected_problematic_terms', '769_original_tweet', '769_rephrased_tweets', '769_suspected_problematic_terms'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['765_original_tweet', '765_rephrased_tweets', '765_suspected_problematic_terms', '766_original_tweet', '766_rephrased_tweets', '766_suspected_problematic_terms', '767_original_tweet', '767_rephrased_tweets', '767_suspected_problematic_terms', '768_original_tweet', '768_rephrased_tweets', '768_suspected_problematic_terms', '769_original_tweet', '769_rephrased_tweets', '769_suspected_problematic_terms'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['765_original_tweet', '765_rephrased_tweets', '765_suspected_problematic_terms', '766_original_tweet', '766_rephrased_tweets', '766_suspected_problematic_terms', '767_original_tweet', '767_rephrased_tweets', '767_suspected_problematic_terms', '768_original_tweet', '768_rephrased_tweets', '768_suspected_problematic_terms', '769_original_tweet', '769_rephrased_tweets', '769_suspected_problematic_terms'])\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 970 to 975\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1050 to 1055\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1145 to 1150\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1170 to 1175\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 1180\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 1181\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 1182\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 1183\n",
      "2023-06-11 20:17:05 WARNING  Cannot extract from dictionary from 1184\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1300 to 1305\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1335 to 1340\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1375 to 1380\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1395 to 1400\n",
      "2023-06-11 20:17:05 WARNING  Tweets contain some duplications, poor quality dropping from 1410 to 1415\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['Rephrased Versions'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['Rephrased Versions'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['Rephrased Versions'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['Rephrased Versions'])\n",
      "2023-06-11 20:17:05 WARNING  Not found in diverse dictionary withdict_keys(['Rephrased Versions'])\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 1635 to 1640\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 1660 to 1665\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['1745', '1746', '1747', '1748', '1749', 'rephrased'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['1745', '1746', '1747', '1748', '1749', 'rephrased'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['1745', '1746', '1747', '1748', '1749', 'rephrased'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['1745', '1746', '1747', '1748', '1749', 'rephrased'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['1745', '1746', '1747', '1748', '1749', 'rephrased'])\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 1800 to 1805\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 1905\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 1906\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 1907\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 1908\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 1909\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'tweet2', 'tweet3', 'tweet4', 'tweet5', 'problematic terms', 'inclusive terms'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'tweet2', 'tweet3', 'tweet4', 'tweet5', 'problematic terms', 'inclusive terms'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'tweet2', 'tweet3', 'tweet4', 'tweet5', 'problematic terms', 'inclusive terms'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'tweet2', 'tweet3', 'tweet4', 'tweet5', 'problematic terms', 'inclusive terms'])\n",
      "2023-06-11 20:17:06 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'tweet2', 'tweet3', 'tweet4', 'tweet5', 'problematic terms', 'inclusive terms'])\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2035\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2036\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2037\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2038\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2039\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 2050 to 2055\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 2240 to 2245\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 2290 to 2295\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 2360 to 2365\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2520\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2521\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2522\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2523\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2524\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 2580 to 2585\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 2650 to 2655\n",
      "2023-06-11 20:17:06 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Tweets', 'Problematic Terms']) from 2660\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2660\n",
      "2023-06-11 20:17:06 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Tweets', 'Problematic Terms']) from 2661\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2661\n",
      "2023-06-11 20:17:06 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Tweets', 'Problematic Terms']) from 2662\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2662\n",
      "2023-06-11 20:17:06 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Tweets', 'Problematic Terms']) from 2663\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2663\n",
      "2023-06-11 20:17:06 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Tweets', 'Problematic Terms']) from 2664\n",
      "2023-06-11 20:17:06 WARNING  Cannot extract from dictionary from 2664\n",
      "2023-06-11 20:17:06 WARNING  Tweets contain some duplications, poor quality dropping from 2665 to 2670\n",
      "2023-06-11 20:17:07 WARNING  Tweets contain some duplications, poor quality dropping from 2815 to 2820\n",
      "2023-06-11 20:17:07 WARNING  Tweets contain some duplications, poor quality dropping from 2865 to 2870\n",
      "2023-06-11 20:17:07 WARNING  Tweets contain some duplications, poor quality dropping from 2920 to 2925\n",
      "2023-06-11 20:17:07 WARNING  Tweets contain some duplications, poor quality dropping from 2995 to 3000\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3010_original_tweet', '3010_rephrased_tweets', '3010_problematic_terms', '3011_original_tweet', '3011_rephrased_tweets', '3011_problematic_terms', '3012_original_tweet', '3012_rephrased_tweets', '3012_problematic_terms', '3013_original_tweet', '3013_rephrased_tweets', '3013_problematic_terms', '3014_original_tweet', '3014_rephrased_tweets', '3014_problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3010_original_tweet', '3010_rephrased_tweets', '3010_problematic_terms', '3011_original_tweet', '3011_rephrased_tweets', '3011_problematic_terms', '3012_original_tweet', '3012_rephrased_tweets', '3012_problematic_terms', '3013_original_tweet', '3013_rephrased_tweets', '3013_problematic_terms', '3014_original_tweet', '3014_rephrased_tweets', '3014_problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3010_original_tweet', '3010_rephrased_tweets', '3010_problematic_terms', '3011_original_tweet', '3011_rephrased_tweets', '3011_problematic_terms', '3012_original_tweet', '3012_rephrased_tweets', '3012_problematic_terms', '3013_original_tweet', '3013_rephrased_tweets', '3013_problematic_terms', '3014_original_tweet', '3014_rephrased_tweets', '3014_problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3010_original_tweet', '3010_rephrased_tweets', '3010_problematic_terms', '3011_original_tweet', '3011_rephrased_tweets', '3011_problematic_terms', '3012_original_tweet', '3012_rephrased_tweets', '3012_problematic_terms', '3013_original_tweet', '3013_rephrased_tweets', '3013_problematic_terms', '3014_original_tweet', '3014_rephrased_tweets', '3014_problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3010_original_tweet', '3010_rephrased_tweets', '3010_problematic_terms', '3011_original_tweet', '3011_rephrased_tweets', '3011_problematic_terms', '3012_original_tweet', '3012_rephrased_tweets', '3012_problematic_terms', '3013_original_tweet', '3013_rephrased_tweets', '3013_problematic_terms', '3014_original_tweet', '3014_rephrased_tweets', '3014_problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Tweets contain some duplications, poor quality dropping from 3305 to 3310\n",
      "2023-06-11 20:17:07 WARNING  Tweets contain some duplications, poor quality dropping from 3410 to 3415\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3470', '3471', '3472', '3473', '3474', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3470', '3471', '3472', '3473', '3474', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3470', '3471', '3472', '3473', '3474', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3470', '3471', '3472', '3473', '3474', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['3470', '3471', '3472', '3473', '3474', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['4055', 'rephrased_4055', '4056', 'rephrased_4056', '4057', 'rephrased_4057', '4058', 'rephrased_4058', '4059', 'rephrased_4059'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['4055', 'rephrased_4055', '4056', 'rephrased_4056', '4057', 'rephrased_4057', '4058', 'rephrased_4058', '4059', 'rephrased_4059'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['4055', 'rephrased_4055', '4056', 'rephrased_4056', '4057', 'rephrased_4057', '4058', 'rephrased_4058', '4059', 'rephrased_4059'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['4055', 'rephrased_4055', '4056', 'rephrased_4056', '4057', 'rephrased_4057', '4058', 'rephrased_4058', '4059', 'rephrased_4059'])\n",
      "2023-06-11 20:17:07 WARNING  Not found in diverse dictionary withdict_keys(['4055', 'rephrased_4055', '4056', 'rephrased_4056', '4057', 'rephrased_4057', '4058', 'rephrased_4058', '4059', 'rephrased_4059'])\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4245 to 4250\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4291\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4292\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4293\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4294\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4330 to 4335\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4365 to 4370\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4400 to 4405\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4415\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4416\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4417\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4418\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4419\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4480 to 4485\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4565 to 4570\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4600', '4601', '4602', '4603', '4604', '4601_rep', '4603_rep', '4604_rep'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4600', '4601', '4602', '4603', '4604', '4601_rep', '4603_rep', '4604_rep'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4600', '4601', '4602', '4603', '4604', '4601_rep', '4603_rep', '4604_rep'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4600', '4601', '4602', '4603', '4604', '4601_rep', '4603_rep', '4604_rep'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4600', '4601', '4602', '4603', '4604', '4601_rep', '4603_rep', '4604_rep'])\n",
      "2023-06-11 20:17:08 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Original_tweet', 'Rephrased_versions', 'Suspected_problematic_terms']) from 4635\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4635\n",
      "2023-06-11 20:17:08 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Original_tweet', 'Rephrased_versions', 'Suspected_problematic_terms']) from 4636\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4636\n",
      "2023-06-11 20:17:08 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Original_tweet', 'Rephrased_versions', 'Suspected_problematic_terms']) from 4637\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4637\n",
      "2023-06-11 20:17:08 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Original_tweet', 'Rephrased_versions', 'Suspected_problematic_terms']) from 4638\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4638\n",
      "2023-06-11 20:17:08 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Original_tweet', 'Rephrased_versions', 'Suspected_problematic_terms']) from 4639\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 4639\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4695', '4696'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4695', '4696'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4695', '4696'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4695', '4696'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['4695', '4696'])\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4700 to 4705\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4875 to 4880\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:08 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets', 'problematic_terms'])\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 4930 to 4935\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 5045 to 5050\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 5060 to 5065\n",
      "2023-06-11 20:17:08 WARNING  Tweets contain some duplications, poor quality dropping from 5180 to 5185\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 5290\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 5291\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 5292\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 5293\n",
      "2023-06-11 20:17:08 WARNING  Cannot extract from dictionary from 5294\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 5335 to 5340\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 5360 to 5365\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 5380 to 5385\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5400\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5401\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5402\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5403\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5404\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5440 Rephrased Versions', '5441 Rephrased Versions', '5442 Rephrased Versions', '5443 Rephrased Version', '5444 Rephrased Version', 'Suspected Problematic Terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5440 Rephrased Versions', '5441 Rephrased Versions', '5442 Rephrased Versions', '5443 Rephrased Version', '5444 Rephrased Version', 'Suspected Problematic Terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5440 Rephrased Versions', '5441 Rephrased Versions', '5442 Rephrased Versions', '5443 Rephrased Version', '5444 Rephrased Version', 'Suspected Problematic Terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5440 Rephrased Versions', '5441 Rephrased Versions', '5442 Rephrased Versions', '5443 Rephrased Version', '5444 Rephrased Version', 'Suspected Problematic Terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5440 Rephrased Versions', '5441 Rephrased Versions', '5442 Rephrased Versions', '5443 Rephrased Version', '5444 Rephrased Version', 'Suspected Problematic Terms'])\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 5490 to 5495\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5660 Original tweet', '5660 Rephrased versions', '5660 Suspected problematic terms', '5661 Original tweet', '5661 Rephrased versions', '5661 Suspected problematic terms', '5662 Original tweet', '5662 Rephrased versions', '5662 Suspected problematic terms', '5663 Original tweet', '5663 Rephrased versions', '5663 Suspected problematic terms', '5664 Original tweet', '5664 Rephrased versions', '5664 Suspected problematic terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5660 Original tweet', '5660 Rephrased versions', '5660 Suspected problematic terms', '5661 Original tweet', '5661 Rephrased versions', '5661 Suspected problematic terms', '5662 Original tweet', '5662 Rephrased versions', '5662 Suspected problematic terms', '5663 Original tweet', '5663 Rephrased versions', '5663 Suspected problematic terms', '5664 Original tweet', '5664 Rephrased versions', '5664 Suspected problematic terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5660 Original tweet', '5660 Rephrased versions', '5660 Suspected problematic terms', '5661 Original tweet', '5661 Rephrased versions', '5661 Suspected problematic terms', '5662 Original tweet', '5662 Rephrased versions', '5662 Suspected problematic terms', '5663 Original tweet', '5663 Rephrased versions', '5663 Suspected problematic terms', '5664 Original tweet', '5664 Rephrased versions', '5664 Suspected problematic terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5660 Original tweet', '5660 Rephrased versions', '5660 Suspected problematic terms', '5661 Original tweet', '5661 Rephrased versions', '5661 Suspected problematic terms', '5662 Original tweet', '5662 Rephrased versions', '5662 Suspected problematic terms', '5663 Original tweet', '5663 Rephrased versions', '5663 Suspected problematic terms', '5664 Original tweet', '5664 Rephrased versions', '5664 Suspected problematic terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['5660 Original tweet', '5660 Rephrased versions', '5660 Suspected problematic terms', '5661 Original tweet', '5661 Rephrased versions', '5661 Suspected problematic terms', '5662 Original tweet', '5662 Rephrased versions', '5662 Suspected problematic terms', '5663 Original tweet', '5663 Rephrased versions', '5663 Suspected problematic terms', '5664 Original tweet', '5664 Rephrased versions', '5664 Suspected problematic terms'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['tweet1_problematic_terms', 'tweet1_rephrased_versions', 'tweet2_problematic_terms', 'tweet2_rephrased_versions', 'tweet3_problematic_terms', 'tweet3_rephrased_versions', 'tweet4_problematic_terms', 'tweet4_rephrased_versions', 'tweet5_problematic_terms', 'tweet5_rephrased_versions'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['tweet1_problematic_terms', 'tweet1_rephrased_versions', 'tweet2_problematic_terms', 'tweet2_rephrased_versions', 'tweet3_problematic_terms', 'tweet3_rephrased_versions', 'tweet4_problematic_terms', 'tweet4_rephrased_versions', 'tweet5_problematic_terms', 'tweet5_rephrased_versions'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['tweet1_problematic_terms', 'tweet1_rephrased_versions', 'tweet2_problematic_terms', 'tweet2_rephrased_versions', 'tweet3_problematic_terms', 'tweet3_rephrased_versions', 'tweet4_problematic_terms', 'tweet4_rephrased_versions', 'tweet5_problematic_terms', 'tweet5_rephrased_versions'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['tweet1_problematic_terms', 'tweet1_rephrased_versions', 'tweet2_problematic_terms', 'tweet2_rephrased_versions', 'tweet3_problematic_terms', 'tweet3_rephrased_versions', 'tweet4_problematic_terms', 'tweet4_rephrased_versions', 'tweet5_problematic_terms', 'tweet5_rephrased_versions'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['tweet1_problematic_terms', 'tweet1_rephrased_versions', 'tweet2_problematic_terms', 'tweet2_rephrased_versions', 'tweet3_problematic_terms', 'tweet3_rephrased_versions', 'tweet4_problematic_terms', 'tweet4_rephrased_versions', 'tweet5_problematic_terms', 'tweet5_rephrased_versions'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:09 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:09 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Versions 1', 'Rephrased Versions 2', 'Problematic Terms']) from 5905\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5905\n",
      "2023-06-11 20:17:09 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Versions 1', 'Rephrased Versions 2', 'Problematic Terms']) from 5906\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5906\n",
      "2023-06-11 20:17:09 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Versions 1', 'Rephrased Versions 2', 'Problematic Terms']) from 5907\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5907\n",
      "2023-06-11 20:17:09 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Versions 1', 'Rephrased Versions 2', 'Problematic Terms']) from 5908\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5908\n",
      "2023-06-11 20:17:09 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Rephrased Versions 1', 'Rephrased Versions 2', 'Problematic Terms']) from 5909\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 5909\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 6000 to 6005\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 6025 to 6030\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 6030 to 6035\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 6075 to 6080\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 6110 to 6115\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 6195 to 6200\n",
      "2023-06-11 20:17:09 WARNING  Tweets contain some duplications, poor quality dropping from 6345 to 6350\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 6445\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 6446\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 6447\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 6448\n",
      "2023-06-11 20:17:09 WARNING  Cannot extract from dictionary from 6449\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 6475 to 6480\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['6565_original_tweet', '6565_rephrased_tweets', '6565_problematic_terms', '6566_original_tweet', '6566_rephrased_tweets', '6566_problematic_terms', '6567_original_tweet', '6567_rephrased_tweets', '6567_problematic_terms', '6568_original_tweet', '6568_rephrased_tweets', '6568_problematic_terms', '6569_original_tweet', '6569_rephrased_tweets', '6569_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['6565_original_tweet', '6565_rephrased_tweets', '6565_problematic_terms', '6566_original_tweet', '6566_rephrased_tweets', '6566_problematic_terms', '6567_original_tweet', '6567_rephrased_tweets', '6567_problematic_terms', '6568_original_tweet', '6568_rephrased_tweets', '6568_problematic_terms', '6569_original_tweet', '6569_rephrased_tweets', '6569_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['6565_original_tweet', '6565_rephrased_tweets', '6565_problematic_terms', '6566_original_tweet', '6566_rephrased_tweets', '6566_problematic_terms', '6567_original_tweet', '6567_rephrased_tweets', '6567_problematic_terms', '6568_original_tweet', '6568_rephrased_tweets', '6568_problematic_terms', '6569_original_tweet', '6569_rephrased_tweets', '6569_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['6565_original_tweet', '6565_rephrased_tweets', '6565_problematic_terms', '6566_original_tweet', '6566_rephrased_tweets', '6566_problematic_terms', '6567_original_tweet', '6567_rephrased_tweets', '6567_problematic_terms', '6568_original_tweet', '6568_rephrased_tweets', '6568_problematic_terms', '6569_original_tweet', '6569_rephrased_tweets', '6569_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['6565_original_tweet', '6565_rephrased_tweets', '6565_problematic_terms', '6566_original_tweet', '6566_rephrased_tweets', '6566_problematic_terms', '6567_original_tweet', '6567_rephrased_tweets', '6567_problematic_terms', '6568_original_tweet', '6568_rephrased_tweets', '6568_problematic_terms', '6569_original_tweet', '6569_rephrased_tweets', '6569_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 6575 to 6580\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6820\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6821\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6822\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6823\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6824\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 6860 to 6865\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 6910 to 6915\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 6920 to 6925\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6935\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6937\n",
      "2023-06-11 20:17:10 WARNING  Cannot extract from dictionary from 6938\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 7060 to 7065\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 7120 to 7125\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 7195 to 7200\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 7220 to 7225\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 7235 to 7240\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['7290_original_tweet', '7290_rephrased_tweets', '7290_problematic_terms', '7291_original_tweet', '7291_rephrased_tweets', '7291_problematic_terms', '7292_original_tweet', '7292_rephrased_tweets', '7292_problematic_terms', '7293_original_tweet', '7293_rephrased_tweets', '7293_problematic_terms', '7294_original_tweet', '7294_rephrased_tweets', '7294_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['7290_original_tweet', '7290_rephrased_tweets', '7290_problematic_terms', '7291_original_tweet', '7291_rephrased_tweets', '7291_problematic_terms', '7292_original_tweet', '7292_rephrased_tweets', '7292_problematic_terms', '7293_original_tweet', '7293_rephrased_tweets', '7293_problematic_terms', '7294_original_tweet', '7294_rephrased_tweets', '7294_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['7290_original_tweet', '7290_rephrased_tweets', '7290_problematic_terms', '7291_original_tweet', '7291_rephrased_tweets', '7291_problematic_terms', '7292_original_tweet', '7292_rephrased_tweets', '7292_problematic_terms', '7293_original_tweet', '7293_rephrased_tweets', '7293_problematic_terms', '7294_original_tweet', '7294_rephrased_tweets', '7294_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['7290_original_tweet', '7290_rephrased_tweets', '7290_problematic_terms', '7291_original_tweet', '7291_rephrased_tweets', '7291_problematic_terms', '7292_original_tweet', '7292_rephrased_tweets', '7292_problematic_terms', '7293_original_tweet', '7293_rephrased_tweets', '7293_problematic_terms', '7294_original_tweet', '7294_rephrased_tweets', '7294_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Not found in diverse dictionary withdict_keys(['7290_original_tweet', '7290_rephrased_tweets', '7290_problematic_terms', '7291_original_tweet', '7291_rephrased_tweets', '7291_problematic_terms', '7292_original_tweet', '7292_rephrased_tweets', '7292_problematic_terms', '7293_original_tweet', '7293_rephrased_tweets', '7293_problematic_terms', '7294_original_tweet', '7294_rephrased_tweets', '7294_problematic_terms'])\n",
      "2023-06-11 20:17:10 WARNING  Tweets contain some duplications, poor quality dropping from 7385 to 7390\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 7540 to 7545\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['original_tweet', 'problematic_terms']) from 7685\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['original_tweet', 'problematic_terms']) from 7686\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['original_tweet', 'problematic_terms']) from 7687\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['original_tweet', 'problematic_terms']) from 7688\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['original_tweet', 'problematic_terms']) from 7689\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['7695_original_tweet', '7695_rephrased_tweets', '7695_problematic_terms', '7696_original_tweet', '7696_rephrased_tweets', '7696_problematic_terms', '7697_original_tweet', '7697_rephrased_tweets', '7697_problematic_terms', '7698_original_tweet', '7698_rephrased_tweets', '7698_problematic_terms', '7699_original_tweet', '7699_rephrased_tweets', '7699_problematic_terms'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['7695_original_tweet', '7695_rephrased_tweets', '7695_problematic_terms', '7696_original_tweet', '7696_rephrased_tweets', '7696_problematic_terms', '7697_original_tweet', '7697_rephrased_tweets', '7697_problematic_terms', '7698_original_tweet', '7698_rephrased_tweets', '7698_problematic_terms', '7699_original_tweet', '7699_rephrased_tweets', '7699_problematic_terms'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['7695_original_tweet', '7695_rephrased_tweets', '7695_problematic_terms', '7696_original_tweet', '7696_rephrased_tweets', '7696_problematic_terms', '7697_original_tweet', '7697_rephrased_tweets', '7697_problematic_terms', '7698_original_tweet', '7698_rephrased_tweets', '7698_problematic_terms', '7699_original_tweet', '7699_rephrased_tweets', '7699_problematic_terms'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['7695_original_tweet', '7695_rephrased_tweets', '7695_problematic_terms', '7696_original_tweet', '7696_rephrased_tweets', '7696_problematic_terms', '7697_original_tweet', '7697_rephrased_tweets', '7697_problematic_terms', '7698_original_tweet', '7698_rephrased_tweets', '7698_problematic_terms', '7699_original_tweet', '7699_rephrased_tweets', '7699_problematic_terms'])\n",
      "2023-06-11 20:17:11 WARNING  Not found in diverse dictionary withdict_keys(['7695_original_tweet', '7695_rephrased_tweets', '7695_problematic_terms', '7696_original_tweet', '7696_rephrased_tweets', '7696_problematic_terms', '7697_original_tweet', '7697_rephrased_tweets', '7697_problematic_terms', '7698_original_tweet', '7698_rephrased_tweets', '7698_problematic_terms', '7699_original_tweet', '7699_rephrased_tweets', '7699_problematic_terms'])\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 7850 to 7855\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 7870 to 7875\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic term', 'Inclusive language version 1', 'Inclusive language version 2', 'Inclusive language version 3']) from 7905\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7905\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic term', 'Inclusive language version 1', 'Inclusive language version 2', 'Inclusive language version 3']) from 7906\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7906\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic term', 'Inclusive language version 1', 'Inclusive language version 2', 'Inclusive language version 3']) from 7907\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7907\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic term', 'Inclusive language version 1', 'Inclusive language version 2', 'Inclusive language version 3']) from 7908\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7908\n",
      "2023-06-11 20:17:11 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic term', 'Inclusive language version 1', 'Inclusive language version 2', 'Inclusive language version 3']) from 7909\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7909\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7910\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7911\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7912\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7913\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 7914\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8165 to 8170\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8200 to 8205\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8220 to 8225\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8375 to 8380\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8385 to 8390\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 8405\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 8406\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 8407\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 8408\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 8409\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8440 to 8445\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8550 to 8555\n",
      "2023-06-11 20:17:11 WARNING  Tweets contain some duplications, poor quality dropping from 8560 to 8565\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 8575\n",
      "2023-06-11 20:17:11 WARNING  Cannot extract from dictionary from 8576\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 8577\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 8578\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 8579\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 8685 to 8690\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 8905 to 8910\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 8980 to 8985\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['rephrased_tweets'])\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9045 to 9050\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9255 to 9260\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9360 to 9365\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'rephrased_tweet1', 'suspected_problematic_terms_tweet1', 'tweet2', 'rephrased_tweet2', 'suspected_problematic_terms_tweet2', 'tweet3', 'rephrased_tweet3', 'suspected_problematic_terms_tweet3', 'tweet4', 'rephrased_tweet4', 'suspected_problematic_terms_tweet4', 'tweet5', 'rephrased_tweet5', 'suspected_problematic_terms_tweet5'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'rephrased_tweet1', 'suspected_problematic_terms_tweet1', 'tweet2', 'rephrased_tweet2', 'suspected_problematic_terms_tweet2', 'tweet3', 'rephrased_tweet3', 'suspected_problematic_terms_tweet3', 'tweet4', 'rephrased_tweet4', 'suspected_problematic_terms_tweet4', 'tweet5', 'rephrased_tweet5', 'suspected_problematic_terms_tweet5'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'rephrased_tweet1', 'suspected_problematic_terms_tweet1', 'tweet2', 'rephrased_tweet2', 'suspected_problematic_terms_tweet2', 'tweet3', 'rephrased_tweet3', 'suspected_problematic_terms_tweet3', 'tweet4', 'rephrased_tweet4', 'suspected_problematic_terms_tweet4', 'tweet5', 'rephrased_tweet5', 'suspected_problematic_terms_tweet5'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'rephrased_tweet1', 'suspected_problematic_terms_tweet1', 'tweet2', 'rephrased_tweet2', 'suspected_problematic_terms_tweet2', 'tweet3', 'rephrased_tweet3', 'suspected_problematic_terms_tweet3', 'tweet4', 'rephrased_tweet4', 'suspected_problematic_terms_tweet4', 'tweet5', 'rephrased_tweet5', 'suspected_problematic_terms_tweet5'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['tweet1', 'rephrased_tweet1', 'suspected_problematic_terms_tweet1', 'tweet2', 'rephrased_tweet2', 'suspected_problematic_terms_tweet2', 'tweet3', 'rephrased_tweet3', 'suspected_problematic_terms_tweet3', 'tweet4', 'rephrased_tweet4', 'suspected_problematic_terms_tweet4', 'tweet5', 'rephrased_tweet5', 'suspected_problematic_terms_tweet5'])\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9595 to 9600\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9600\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9601\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9602\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9603\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9604\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9625 to 9630\n",
      "2023-06-11 20:17:12 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic terms', 'Rephrased tweets']) from 9630\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9630\n",
      "2023-06-11 20:17:12 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic terms', 'Rephrased tweets']) from 9631\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9631\n",
      "2023-06-11 20:17:12 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic terms', 'Rephrased tweets']) from 9632\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9632\n",
      "2023-06-11 20:17:12 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic terms', 'Rephrased tweets']) from 9633\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9633\n",
      "2023-06-11 20:17:12 WARNING  Tweets Rephrase keys not able to extract dict_keys(['Problematic terms', 'Rephrased tweets']) from 9634\n",
      "2023-06-11 20:17:12 WARNING  Cannot extract from dictionary from 9634\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9695 to 9700\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9870 to 9875\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9960 to 9965\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9980 to 9985\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['9985', '9988', '9989'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['9985', '9988', '9989'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['9985', '9988', '9989'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['9985', '9988', '9989'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['9985', '9988', '9989'])\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 9995 to 10000\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 10035 to 10040\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['10110', '10111', '10112', '10113', '10114', 'problematic_terms'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['10110', '10111', '10112', '10113', '10114', 'problematic_terms'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['10110', '10111', '10112', '10113', '10114', 'problematic_terms'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['10110', '10111', '10112', '10113', '10114', 'problematic_terms'])\n",
      "2023-06-11 20:17:12 WARNING  Not found in diverse dictionary withdict_keys(['10110', '10111', '10112', '10113', '10114', 'problematic_terms'])\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 10200 to 10205\n",
      "2023-06-11 20:17:12 WARNING  Tweets contain some duplications, poor quality dropping from 10220 to 10225\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10295 to 10300\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10300 to 10305\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10325 to 10330\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10355 to 10360\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10405 to 10410\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10450 to 10455\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10470 to 10475\n",
      "2023-06-11 20:17:13 WARNING  Cannot extract from dictionary from 10480\n",
      "2023-06-11 20:17:13 WARNING  Cannot extract from dictionary from 10481\n",
      "2023-06-11 20:17:13 WARNING  Cannot extract from dictionary from 10482\n",
      "2023-06-11 20:17:13 WARNING  Cannot extract from dictionary from 10483\n",
      "2023-06-11 20:17:13 WARNING  Cannot extract from dictionary from 10484\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10545 to 10550\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10630 to 10635\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10705 to 10710\n",
      "2023-06-11 20:17:13 WARNING  Tweets contain some duplications, poor quality dropping from 10730 to 10735\n",
      "2023-06-11 20:17:13 INFO     Percentage of GPT Rephrase of Tweets: 98.27%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import advertools as adv\n",
    "\n",
    "rephrase_keys = ['rephrased_tweets', 'Rephrased versions', 'rephrased', 'rephrased_versions',\n",
    "                     'rephrased versions', 'Rephrased Versions', 'rephrasedVersions', 'inclusive_versions',\n",
    "                     'Inclusive rephrased versions', 'rephrasedTweet', 'rephrasedTweets', 'inclusive_rephrased_tweets'\n",
    "                    ]\n",
    "rephrase_count = ['rephrased_tweet_', 'rephrased_', 'rephrased', 'Rephrased', 'Rephrased ', 'Rephrased tweet ', \n",
    "                  'rephrased_version_', 'rephrased_tweet', 'Rephrased Tweet ', 'inclusive_tweet_', \n",
    "                  'Rephrased Version ']\n",
    "counter = ['1', '2', '3']\n",
    "\n",
    "def fix_keys(j):\n",
    "    fixed = {}\n",
    "    for k in j.keys():\n",
    "        k_fixed = re.findall(r'\\d+', k)[0]\n",
    "        fixed[k_fixed] = j[k]\n",
    "    return fixed\n",
    "\n",
    "def __rephrase_tweet_dict__(i, t_info, offset):\n",
    "    out = None\n",
    "    found = False\n",
    "    for r in rephrase_keys:\n",
    "        if r in t_info:\n",
    "            out = t_info[r]\n",
    "            if type(out)==str:\n",
    "                out = [out]\n",
    "            if type(out[0]) == dict: # multilevel\n",
    "                out = [out[i]['tweet'] for i in range(0, len(out))]\n",
    "            found = True\n",
    "            break\n",
    "\n",
    "    if not found:\n",
    "        l = []\n",
    "        for r in rephrase_count:\n",
    "            for c in counter:\n",
    "                rc = r+c\n",
    "                if rc in t_info:\n",
    "                    l.append(t_info[rc])\n",
    "                    found = True\n",
    "        if found:\n",
    "            out = l\n",
    "\n",
    "    if not found:\n",
    "        logging.warning('Tweets Rephrase keys not able to extract ' + str(t_info.keys()) + ' from '  + str(i+offset))\n",
    "    return out\n",
    "\n",
    "def __rephrased_tweet_str_followed_by_digit__(t_info):\n",
    "    out = None\n",
    "    l = []\n",
    "    found = False\n",
    "    for r in rephrase_keys + ['Inclusive Rephrasing', 'Rephrased Tweet', 'Rephrased Version', 'Revised Tweet', 'Inclusive Rephrase',\n",
    "                            'Inclusive language rephrased version', 'Inclusive version', 'Inclusive rephrased tweet', \n",
    "                             ]:\n",
    "        # followed by digit\n",
    "        for e in t_info:\n",
    "            if type(e) == str:\n",
    "                s = re.search(r'(' + r + '\\s*)(\\d:\\s*)', e, re.IGNORECASE)\n",
    "                if not s is None and s.span()[0]==0:\n",
    "                    # print('yes', e[0:s.span()[1]])\n",
    "                    l.append(e[s.span()[1]:])\n",
    "                    found = True\n",
    "        if l:\n",
    "            out=l\n",
    "            break\n",
    "    return out, found\n",
    "\n",
    "def __safe__(v):\n",
    "    if v.lower()=='none':\n",
    "        return ''\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def __rephrased_tweet_str_not_followed_by_digit__(t_info):\n",
    "    out = None\n",
    "    l = []\n",
    "    found = False\n",
    "    break_now = False\n",
    "    for r in set(map(str.lower, rephrase_keys+ ['Rephrased versions', 'Alternative rephrased tweet', 'Alternative', 'Rephrased tweets', \n",
    "                             'Rephrased tweet', 'Rephrased tweet\\(s\\)', 'Rephrased tweets', 'Inclusive Language', \n",
    "                             'Inclusive rephrased tweets', 'Inclusive versions', 'Rephrased tweet options', \n",
    "                             'Inclusive rephrased version', 'Inclusive language tweet', 'Inclusive language alternatives',\n",
    "                             '[\\w\\s]*Rephrased version'])):\n",
    "        # not followed by a digit and can take other terms\n",
    "        for n, e in enumerate(t_info):\n",
    "            if type(e) == str:\n",
    "                s = re.search(r'(.*' + r + '\\s*)(:\\s*)', e, re.IGNORECASE)\n",
    "                if not s is None and s.span()[0]==0:\n",
    "                    t = e[s.span()[1]:]\n",
    "                    if len(t.strip()):\n",
    "                        l.append(__safe__(t))\n",
    "                        # print(t, t_info)\n",
    "                        found = True\n",
    "                    elif n==0 or n>0:  # match lst 0 matches rephrase key, and following contains items contains rephrased versions\n",
    "                        for i in range(n+1, len(t_info)):\n",
    "                            if t_info[i].strip()[0] == '-':\n",
    "                                l.append(t_info[i].strip()[1:])\n",
    "                                found = True\n",
    "                            elif re.search(r\"(^\\s*\\d\\.)(.*)\", t_info[i]): # check 1. tweet\n",
    "                                l.append(re.search(r\"(^\\s*\\d\\.)(.*)\", t_info[i]).group(2))\n",
    "                                found = True\n",
    "                            elif (re.findall(\"@([a-zA-Z0-9_]{1,50})\", t_info[i]) or re.findall(\"#([a-zA-Z0-9_]{1,50})\", t_info[i]) \n",
    "                                  or len(t_info[i].split(' '))>5 or adv.extract_emoji(t_info[i])) : # check if text is a tweet through ht, men, emoji or more than 5 words\n",
    "                                l.append(t_info[i])\n",
    "                                found = True\n",
    "                    if found:\n",
    "                        # \n",
    "                        break_now = True\n",
    "                        # if n==2:\n",
    "                        #     print(id, t_info, l)\n",
    "                        break\n",
    "        if break_now:\n",
    "            break\n",
    "\n",
    "    if l:\n",
    "        out=l\n",
    "        # print(id, l, t_info)\n",
    "    return out, found\n",
    "\n",
    "def __rephrase_tweet_list__(id, t_info, offset):\n",
    "    out = None\n",
    "    found = False\n",
    "    if len(t_info) > 0 and type(t_info[0])==dict:\n",
    "        # l = []\n",
    "        for i in range(0, len(t_info)):\n",
    "            for r in rephrase_keys + ['rephrased_tweet', 'tweet']:\n",
    "                if r in t_info[i]:\n",
    "                    # print('--', t_info[i][r])\n",
    "                    # l.append(t_info[i][r])\n",
    "                    out = t_info[i][r]\n",
    "                    found = True\n",
    "                    break\n",
    "        # if found:\n",
    "        #     out = l\n",
    "    elif len(t_info)==0:\n",
    "        # print(id)\n",
    "        out = []\n",
    "    elif len(t_info) > 1:\n",
    "        l = []\n",
    "        out, found = __rephrased_tweet_str_followed_by_digit__(t_info)\n",
    "        if not found:\n",
    "            out, found = __rephrased_tweet_str_not_followed_by_digit__(t_info)\n",
    "        if not found:\n",
    "            if len(t_info):\n",
    "                1\n",
    "                # print(t_info, id)\n",
    "                # for e in t_info:\n",
    "                #     if e.find('1:')>-1:\n",
    "                #         print(t_info)\n",
    "                #         break\n",
    "    return out\n",
    "\n",
    "def get_rephrase_tweets(i, t_info, offset):\n",
    "    out = None\n",
    "    if type(t_info)==dict:\n",
    "        out = __rephrase_tweet_dict__(i, t_info, offset)\n",
    "    elif (type(t_info)==list):\n",
    "        out = __rephrase_tweet_list__(i, t_info, offset)\n",
    "    else:\n",
    "        logging.warning('Ignoring GPT Tweet of ' + str(type(t_info)) + ' type from ' + str(i+offset))\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_flattened_list(nested_list):\n",
    "    lst = []\n",
    "    if type(nested_list) == str:\n",
    "        return [nested_list]\n",
    "    for l in nested_list:\n",
    "        if type(l)==list:\n",
    "            lst.extend(l)\n",
    "        else:\n",
    "            lst.append(l)\n",
    "    return lst\n",
    "\n",
    "\n",
    "def check_duplicates(out_tweet, start_id, bunch_size):\n",
    "    z = [out_tweet[i] for i in range(start_id, start_id + bunch_size) if i in out_tweet]\n",
    "    if len(get_flattened_list(z)) == len(set(get_flattened_list(z))):\n",
    "        return out_tweet\n",
    "    else:\n",
    "        for i in range(start_id, start_id + bunch_size):\n",
    "            out_tweet[i] = ''\n",
    "    logging.warning('Tweets contain some duplications, poor quality dropping from ' + str(start_id) + ' to '+ str(start_id + bunch_size))\n",
    "    return out_tweet      \n",
    "    \n",
    "\n",
    "def extract_json(it, bunch_size, out_tweet):\n",
    "    start_id = int(it[0])\n",
    "    # if not start_id in [6995]:#30, 13240]: #[19910, 240, 13405, 0, 1245]:\n",
    "    #     return out_tweet\n",
    "    j = json.loads(it[1])\n",
    "\n",
    "    # print(start_id, len(j))\n",
    "    \n",
    "    if bunch_size == len(j):\n",
    "        # return out_tweet\n",
    "        if type(j)==dict:\n",
    "            j = fix_keys(j)\n",
    "            # print(j.keys())\n",
    "            # print(str(start_id) in j)\n",
    "            if(str(start_id) in j):\n",
    "                offset = 0\n",
    "            else:\n",
    "                offset = start_id - 1\n",
    "            for i in range(start_id, start_id + bunch_size):\n",
    "                t_info = j[str(i - offset)]\n",
    "                out = get_rephrase_tweets(i, t_info, offset)\n",
    "                # print('---', out)\n",
    "                if not out is None:\n",
    "                    out_tweet[i] = get_flattened_list(out)\n",
    "                else:\n",
    "                    # print(j)\n",
    "                    # print('dict', i)\n",
    "                    logging.warning('Cannot extract from dictionary from ' + str(i))\n",
    "            out_tweet = check_duplicates(out_tweet, start_id, bunch_size)\n",
    "        else:\n",
    "            # print(type(j), start_id)\n",
    "            # print(len(j))\n",
    "            for i in range(0, bunch_size):\n",
    "                t_info = j[i]\n",
    "                out = get_rephrase_tweets(i, t_info, start_id)\n",
    "                if not out is None:\n",
    "                    out_tweet[start_id+i] = out\n",
    "                else:\n",
    "                    print('list', start_id+i)\n",
    "    elif type(j)==dict:\n",
    "        # return out_tweet\n",
    "        if 'tweets' in j and len(j['tweets']) == bunch_size:\n",
    "            # return out_tweet\n",
    "            # print(start_id, len(j['tweets']))\n",
    "            j = j['tweets']\n",
    "            for i in range(0, bunch_size):\n",
    "                t_info = j[i]\n",
    "                out = get_rephrase_tweets(i, t_info, start_id)\n",
    "                if not out is None:\n",
    "                    out_tweet[start_id+i] = out\n",
    "                else:\n",
    "                    pass\n",
    "                    # print('out list', start_id+i, t_info)\n",
    "        else:\n",
    "            out_tweet = extract_from_diverse_dict(j, start_id, bunch_size, out_tweet)\n",
    "    else:\n",
    "        print('Non Json type', j)\n",
    "                \n",
    "    return out_tweet\n",
    "\n",
    "def extract_from_diverse_dict(j, start_id, bunch_size, out_tweet):\n",
    "    # print(start_id, j.keys())\n",
    "    for i in range(start_id, start_id + bunch_size):\n",
    "        found = False\n",
    "        keys = [str(i), str(i) + '.']\n",
    "        for k in keys:\n",
    "            if k in j:\n",
    "                t_info = j[k]\n",
    "                if type(t_info)==list and len(t_info)==3:\n",
    "                    out = t_info\n",
    "                    found = True\n",
    "                else:\n",
    "                    out, found = __rephrased_tweet_str_followed_by_digit__(t_info)\n",
    "                if found:\n",
    "                    out_tweet[i] = out\n",
    "                    break\n",
    "    \n",
    "    if not found:\n",
    "        wrong = False\n",
    "        for i in range(start_id, start_id + bunch_size):\n",
    "            found = False\n",
    "            for k in j.keys():\n",
    "                for r in set(rephrase_keys + ['Rephrased tweets', 'tweet_rephrased', 'tweets_rephrased']):\n",
    "                    # print('(' + str(i) + '.*' + r + ')|(' + r + '.*' + str(i) +')')\n",
    "                    # pattern = r'(' + str(i) + '.*' + r + ')|(' + r + '.*' + str(i) +')|(^' + r + '$)'\n",
    "                    pattern_without_tweet_id = r'(^' + r + '$)'\n",
    "                    pattern_with_tweet_id = r'(' + str(i) + '.*' + r + ')|(' + r + '.*' + str(i) +')'\n",
    "                    if re.search(pattern_without_tweet_id, k, re.IGNORECASE):\n",
    "                        if i in out_tweet and type(j[k])==str:\n",
    "                            out_tweet[i].append(j[k])\n",
    "                        elif type(j[k])==str:\n",
    "                            out_tweet[i] = [j[k]]\n",
    "                        else:\n",
    "                            # print(i)\n",
    "                            # print(k, pattern_without_tweet_id)\n",
    "                            v = multi_level_rephrased(j[k], i-start_id, i, with_digit=False)\n",
    "                            if v:\n",
    "                                out_tweet[i] = v\n",
    "                            else:\n",
    "                                wrong = True\n",
    "                                break\n",
    "                        found = True\n",
    "                        break\n",
    "                    if re.search(pattern_with_tweet_id, k, re.IGNORECASE):\n",
    "                        if i in out_tweet and type(j[k])==str:\n",
    "                            out_tweet[i].append(j[k])\n",
    "                        elif type(j[k])==str:\n",
    "                            out_tweet[i] = [j[k]]\n",
    "                        else:\n",
    "                            # print(i)\n",
    "                            # print(k, pattern_with_tweet_id)\n",
    "                            v = multi_level_rephrased(j[k], i-start_id, i, with_digit=True)\n",
    "                            if v:\n",
    "                                out_tweet[i] = v\n",
    "                            else:\n",
    "                                wrong = True\n",
    "                                break\n",
    "                        found = True\n",
    "                        break\n",
    "            if not found and not wrong:\n",
    "                for r in rephrase_keys:\n",
    "                    keys = [str(i) + '. ' + r, r]\n",
    "                    for k in keys:\n",
    "                        if k in j:\n",
    "                            out_tweet[i] = j[k]\n",
    "                            found = True\n",
    "                            break\n",
    "                        if found:\n",
    "                            break\n",
    "            if not found or not wrong:\n",
    "                # print(i, 'not found', j.keys())\n",
    "                if wrong:\n",
    "                    logging.warning('Not well formed Json in the diverse dictionary with' + str(j.keys()))\n",
    "                else:\n",
    "                    logging.warning('Not found in diverse dictionary with' + str(j.keys()))\n",
    "    return out_tweet\n",
    "\n",
    "def multi_level_rephrased(v, i, idx, with_digit=True):\n",
    "    lst = []\n",
    "    if type(v)==list:\n",
    "        if type(v[0]) == str:\n",
    "            s1 = re.search('^(\\d+).\\s*(.*)$', v[0], re.IGNORECASE)\n",
    "            if s1:\n",
    "                l = []\n",
    "                for cnt in range(0, len(v)):\n",
    "                    s1 = re.search('^(\\d+).\\s*(.*)$', v[cnt], re.IGNORECASE)\n",
    "                    if str(idx) == s1.group(1):\n",
    "                        l.append(s1.group(2))\n",
    "                # print(l)\n",
    "                # print(idx, s1.group(1))\n",
    "                return l\n",
    "            else:\n",
    "                if with_digit:\n",
    "                    # print(with_digit, v, idx)\n",
    "                    return v\n",
    "                else:\n",
    "                    if not len(v) == 5:\n",
    "                        return None\n",
    "                    # print(with_digit, v[i], idx)\n",
    "                    if type(v[i])==str:\n",
    "                        return [v[i]]\n",
    "                    else:\n",
    "                        return v[i]\n",
    "                \n",
    "#                 if len(v) == 1:\n",
    "#                     return v\n",
    "#                 else:\n",
    "                    \n",
    "#                     return v[i]\n",
    "            \n",
    "        else:\n",
    "            for r in set(rephrase_keys + ['tweet', 'text', 'rephrased_version', 'rephrased_tweet']):\n",
    "                if r in v[i]:\n",
    "                    out = v[i][r]\n",
    "                    if type(out)==str:\n",
    "                        out = [out]\n",
    "                    return out\n",
    "            # try:\n",
    "            #     # for r in set(rephrase_keys + ['tweet', 'text']):\n",
    "            #     #     return [v[i][r]]\n",
    "            #     for r in set(rephrase_keys + ['tweet', 'text', 'rephrased_version', 'rephrased_tweet']):\n",
    "            #         if r in v[i]:\n",
    "            #             return [v[i][r]]\n",
    "            #     1/0\n",
    "            # except:\n",
    "            #     print(idx)\n",
    "            #     print(v[i])\n",
    "            #     for r in set(['tweet']):\n",
    "            #         return [v[i][r]]\n",
    "    return None\n",
    "        \n",
    "    \n",
    "\n",
    "def arrange_tweets(bunch_size=5):\n",
    "    out_tweet = {}\n",
    "    for it in valid_tweets.items():\n",
    "        out_tweet = extract_json(it, bunch_size, out_tweet)\n",
    "    p = str(round((len(out_tweet.keys()))/(len(valid_tweets.keys())*5)*100, 2)) +'%'\n",
    "    logging.info('Percentage of GPT Rephrase of Tweets: ' + p)\n",
    "    return out_tweet\n",
    "\n",
    "\n",
    "rephrase_tweet_gpt = arrange_tweets(bunch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11ea8b69-fa94-418d-934a-b0ce5b706f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display(rephrase_tweet_gpt[16710])\n",
    "# print(valid_tweets['16710'])\n",
    "# display(rephrase_tweet_gpt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a2a446-ece6-44a5-857e-cc7159f9c43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display(rephrase_tweet_gpt[17480])\n",
    "# print(valid_tweets['17480'])\n",
    "# display(rephrase_tweet_gpt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58dd4428-9ce1-4998-9f00-5e3b6830272d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display(rephrase_tweet_gpt[20115])\n",
    "# print(valid_tweets['20115'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de9eb9d-9394-44fd-99e1-fce02596503c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8830"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rephrase_tweet_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d489fc-34df-49e7-b9ea-148cd3e1f24f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8985, 10780)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_tweets)*5, max(map(int, valid_tweets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b02e01b-3e97-4367-b194-1e18123e0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in map(int, valid_tweets.keys()):\n",
    "#     if not k in rephrase_tweet_gpt:\n",
    "#         print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a28039fa-c33a-4e8f-a2d8-ed715ab6645d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# offensive derogatory <-- check and also empty ones\n",
    "# search for Suspected problematic term:\n",
    "# 140 only extracts one rephrased version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d54c36-a76c-422b-8dc7-db00963987f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contains_filtered_words(lst):\n",
    "    # filter_list = ['offensive', 'derogatory', 'problematic terms*']\n",
    "    # filter_list = ['offensive']\n",
    "    filter_list = ['problematic terms*']\n",
    "    for f in filter_list:\n",
    "        pattern = '\\\\b' + f +'\\\\b'\n",
    "        # print(pattern)\n",
    "        for e in lst:\n",
    "            if re.search(pattern, e, re.IGNORECASE):\n",
    "                return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "contains_filtered_words(['This person is arguing with my dad. [problematic term: bitchh]', \"If you associate with someone who is not cool, you are not cool either.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29aff354-1ca4-4aba-b88c-8a823b32d0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 20:17:23 INFO     Error Stats: {'empty': 517, 'filtered': 178}\n",
      "2023-06-11 20:17:23 INFO     Percentage of Filtered GPT Rephrase of Tweets: 90.54%\n"
     ]
    }
   ],
   "source": [
    "filtered_rephrase_tweet_gpt = {}\n",
    "def error_stats():\n",
    "    \n",
    "    error = {'empty': 0, 'filtered': 0} \n",
    "    for i, l in rephrase_tweet_gpt.items():\n",
    "        try:\n",
    "            if len(l) ==0 or len(''.join(l))==0:\n",
    "                # print('-->', i, l)\n",
    "                error['empty'] += 1\n",
    "                1\n",
    "            elif contains_filtered_words(l):\n",
    "                # print(i, 'ignore', l)\n",
    "                error['filtered'] += 1\n",
    "                1\n",
    "            # elif len(l)==4:\n",
    "            #     print(i, l)\n",
    "            #     1\n",
    "            else:\n",
    "                filtered_rephrase_tweet_gpt[i] = l\n",
    "        except:\n",
    "            pass\n",
    "            # print(i, l)\n",
    "\n",
    "    out_file = open(gpt_filtered_rephrase_tweets_file, \"w\")\n",
    "    json.dump(filtered_rephrase_tweet_gpt, out_file, indent = 2)\n",
    "    out_file.close()\n",
    "\n",
    "    logging.info('Error Stats: ' + str(error))\n",
    "    p = str(round(len(filtered_rephrase_tweet_gpt)/ (len(valid_tweets)*5 )*100, 2)) +'%'\n",
    "    logging.info('Percentage of Filtered GPT Rephrase of Tweets: ' + p)\n",
    "    \n",
    "error_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65d65553-00f8-4094-9c35-dca41afc333b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8135\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_rephrase_tweet_gpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee91f642-445d-40cf-8993-2f7971637b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "8135/10780"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
