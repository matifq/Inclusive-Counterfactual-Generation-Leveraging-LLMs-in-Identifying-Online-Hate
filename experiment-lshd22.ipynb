{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c2c19-95d7-47d5-9d8c-00b179b83a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install vaderSentiment --quiet\n",
    "!pip install textstat --quiet\n",
    "!pip install nltk --quiet\n",
    "!pip install tpot --quiet\n",
    "!pip install seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b71739-66be-47d2-934e-5047eab61a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from config import LSHS_DATAFILE, gpt_filtered_rephrase_lshs_file\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44b6745-28d9-439b-8423-560034f1e87f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/atif/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/atif/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1436210b-642c-4d22-9e0f-720489b70a05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "#     level=logging.INFO,\n",
    "#     datefmt='%Y-%m-%d %H:%M:%S')\n",
    "# # The default levels are DEBUG, INFO, WARNING, ERROR, and CRITICAL.\n",
    "# print(logging.WARNING)\n",
    "# logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d6c6e2-3c9a-48d0-b5bb-a389b5dce5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "gpt_filtered_rephrase_tweets_file = gpt_filtered_rephrase_lshs_file\n",
    "out_file = open(gpt_filtered_rephrase_tweets_file, \"r\")\n",
    "filtered_rephrase_tweet_gpt = json.load(out_file)\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff75588-e4db-4f2a-87cf-0f49f383acf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender (9454, 4)\n",
      "Religion (10869, 4)\n",
      "Race (12013, 4)\n",
      "Politics (11018, 4)\n",
      "Sports (12306, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(LSHS_DATAFILE)\n",
    "domains = df['Domain'].unique().tolist()\n",
    "for d in domains:\n",
    "    print(d, df[df['Domain'] == d].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933cc930-8e57-4542-b945-b93722434f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1344706773245038592</td>\n",
       "      <td>WATCH: Video previews #SurreyBC-shot film to f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1344706877217792005</td>\n",
       "      <td>Men and women donâ€™t have to solve their proble...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1344707261155962880</td>\n",
       "      <td>At last I awake, very queer about the head, as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1344707529213792256</td>\n",
       "      <td>WATCH: Video previews Surrey-shot film to focu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gender</td>\n",
       "      <td>1344709019865403394</td>\n",
       "      <td>heteronormativity is killing my people. how so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Domain              TweetID   \n",
       "0  Gender  1344706773245038592  \\\n",
       "1  Gender  1344706877217792005   \n",
       "2  Gender  1344707261155962880   \n",
       "3  Gender  1344707529213792256   \n",
       "4  Gender  1344709019865403394   \n",
       "\n",
       "                                               Tweet  Label  \n",
       "0  WATCH: Video previews #SurreyBC-shot film to f...      0  \n",
       "1  Men and women donâ€™t have to solve their proble...      0  \n",
       "2  At last I awake, very queer about the head, as...      0  \n",
       "3  WATCH: Video previews Surrey-shot film to focu...      0  \n",
       "4  heteronormativity is killing my people. how so...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9f0675-8550-4fc6-8a6a-4304c4f01943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "\n",
    "\n",
    "    #############LINE FIXED: * REPLACED WITH +##################### PREVIOUS::: tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]+\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "\n",
    "    #############LINE FIXED: * REPLACED WITH +##################### PREVIOUS::: tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]+\", tweet.lower())).strip()\n",
    "    return tweet.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d61cb2a3-97ed-4bbc-aa6f-ed1d4e78a4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now get other features\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    \"\"\"\n",
    "    Accepts a text string and replaces:\n",
    "    1) urls with URLHERE\n",
    "    2) lots of whitespace with one instance\n",
    "    3) mentions with MENTIONHERE\n",
    "    4) hashtags with HASHTAGHERE\n",
    "\n",
    "    This allows us to get standardized counts of urls and mentions\n",
    "    Without caring about specific people mentioned.\n",
    "    \n",
    "    Returns counts of urls, mentions, and hashtags.\n",
    "    \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    \"\"\"This function takes a string and returns a list of features.\n",
    "    These include Sentiment scores, Text and Readability scores,\n",
    "    as well as Twitter specific features\"\"\"\n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "    \n",
    "    words = preprocess(tweet) #Get text only\n",
    "    \n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6953610f-d140-4baf-af43-2d642e2d82ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Features:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "        tokenizer=tokenize,\n",
    "        preprocessor=preprocess,\n",
    "        ngram_range=(1, 3),\n",
    "        stop_words=stopwords,\n",
    "        use_idf=True,\n",
    "        smooth_idf=False,\n",
    "        norm=None,\n",
    "        decode_error='replace',\n",
    "        max_features=10000,\n",
    "        min_df=5,\n",
    "        max_df=0.75\n",
    "        )\n",
    "        \n",
    "        #We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
    "        self.pos_vectorizer = TfidfVectorizer(\n",
    "        tokenizer=None,\n",
    "        lowercase=False,\n",
    "        preprocessor=None,\n",
    "        ngram_range=(1, 3),\n",
    "        stop_words=None,\n",
    "        use_idf=False,\n",
    "        smooth_idf=False,\n",
    "        norm=None,\n",
    "        decode_error='replace',\n",
    "        max_features=5000,\n",
    "        min_df=5,\n",
    "        max_df=0.75,\n",
    "        )\n",
    "        \n",
    "        self.other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \\\n",
    "                        \"vader compound\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]\n",
    "        \n",
    "    def __tfidf__(self, tweets, isTrain=True):\n",
    "        #Construct tfidf matrix and get relevant scores\n",
    "        if isTrain:\n",
    "            return self.vectorizer.fit_transform(tweets).toarray()\n",
    "        else:\n",
    "            return self.vectorizer.transform(tweets).toarray()\n",
    "    \n",
    "    def __get_pos_tags__(self, tweets):\n",
    "        #Get POS tags for tweets and save as a string\n",
    "        tweet_tags = []\n",
    "        for t in tweets:\n",
    "            tokens = basic_tokenize(preprocess(t))\n",
    "            tags = nltk.pos_tag(tokens)\n",
    "            tag_list = [x[1] for x in tags]\n",
    "            tag_str = \" \".join(tag_list)\n",
    "            tweet_tags.append(tag_str)\n",
    "        return tweet_tags\n",
    "    \n",
    "    def __pos_tags__(self, tweets, isTrain=True):\n",
    "        tweet_tags = self.__get_pos_tags__(tweets)\n",
    "        \n",
    "        #Construct POS TF matrix and get vocab dict\n",
    "        if isTrain:\n",
    "            return self.pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()\n",
    "        else:\n",
    "            return self.pos_vectorizer.transform(pd.Series(tweet_tags)).toarray()\n",
    "    \n",
    "    def get_features(self, tweets, isTrain=True):\n",
    "        tfidf = self.__tfidf__(tweets, isTrain=isTrain)\n",
    "        pos = self.__pos_tags__(tweets, isTrain=isTrain)\n",
    "        self.feats = get_feature_array(tweets)\n",
    "        \n",
    "        #Now join them all up\n",
    "        # recover ids for mapping\n",
    "        # ids = np.array(tweets.index.to_list())\n",
    "        # ids = ids.reshape(ids.shape[0], 1)\n",
    "        # M = np.concatenate([ids, tfidf,pos,feats],axis=1)\n",
    "        M = np.concatenate([tfidf, pos, self.feats],axis=1)\n",
    "        \n",
    "        X = pd.DataFrame(M)\n",
    "        \n",
    "        return X\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8eae50-4ace-44fb-ae31-7d9088925c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X, y = df[['Domain', 'Tweet']], df['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8538a42c-2aad-4033-86e8-f1ca50239c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HateLabel\tFinal hate label decision 0-Normal, 1-Offensive, 2-Hate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45aaa4-b29a-41a5-bd6e-7e176999bcf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Our Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ed865f-c2b9-4e32-85fd-749b1660daf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CF_LABEL = 0\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55a2a446-ece6-44a5-857e-cc7159f9c43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    44874\n",
      "1     9669\n",
      "2     1117\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10786, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Label'].value_counts())\n",
    "problematic_df = df[df['Label']>0]\n",
    "problematic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8651df44-7400-4918-8dfc-1c42bbf8d9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55660, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65245a9b-7012-4de0-8608-91a8dce64f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55655</th>\n",
       "      <td>Sports</td>\n",
       "      <td>1277315350254751747</td>\n",
       "      <td>Fuck off Gayle, professional footballer and yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55656</th>\n",
       "      <td>Sports</td>\n",
       "      <td>1277319456071581698</td>\n",
       "      <td>Omo I hate mancity abeg. What is this fluid fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55657</th>\n",
       "      <td>Sports</td>\n",
       "      <td>1277316487271854082</td>\n",
       "      <td>I hate playing Manchester United again</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55658</th>\n",
       "      <td>Sports</td>\n",
       "      <td>1277319975305445381</td>\n",
       "      <td>I'll get trolled to fuck but I'd give anything...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55659</th>\n",
       "      <td>Sports</td>\n",
       "      <td>1277311388759863296</td>\n",
       "      <td>Chelsea though! I think I hate football. ðŸ™„ #mufc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Domain              TweetID   \n",
       "55655  Sports  1277315350254751747  \\\n",
       "55656  Sports  1277319456071581698   \n",
       "55657  Sports  1277316487271854082   \n",
       "55658  Sports  1277319975305445381   \n",
       "55659  Sports  1277311388759863296   \n",
       "\n",
       "                                                   Tweet  Label  \n",
       "55655  Fuck off Gayle, professional footballer and yo...      1  \n",
       "55656  Omo I hate mancity abeg. What is this fluid fo...      2  \n",
       "55657             I hate playing Manchester United again      2  \n",
       "55658  I'll get trolled to fuck but I'd give anything...      1  \n",
       "55659   Chelsea though! I think I hate football. ðŸ™„ #mufc      2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problematic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75f78bdb-cf13-452f-9400-b134e55a7b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tweets():\n",
    "    gpt_counterfactual_tweets = {}\n",
    "    tot = problematic_df.shape[0]\n",
    "    # print(tot)\n",
    "    for i in range(0, tot):\n",
    "        idx = problematic_df.iloc[i].name\n",
    "        if str(i) in filtered_rephrase_tweet_gpt:\n",
    "            gpt_counterfactual_tweets[idx] = filtered_rephrase_tweet_gpt[str(i)]\n",
    "    return gpt_counterfactual_tweets\n",
    "    \n",
    "gpt_counterfactual_tweets = get_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe652ef-b511-48f8-bd32-13f821f905d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8135"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt_counterfactual_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b13567a-c2bd-481a-878f-1efd8380f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import mosestokenizer\n",
    "import numpy as np\n",
    "\n",
    "def get_offensive_words():\n",
    "    _df = pd.read_csv(config.en_swear_words_datafile, index_col=0)\n",
    "    \n",
    "    s = np.logical_or(_df['Level of offensiveness']=='Strongest words', _df['Level of offensiveness']=='Strong words')\n",
    "    # display(_df[s]['Word'].to_list())\n",
    "    wd_list = _df['Word'].to_list()\n",
    "    \n",
    "    _df = pd.read_csv(config.en_profanity_datafile, index_col=None)\n",
    "    s = _df['severity_description'] == 'Severe'\n",
    "    # wd_list.extend(_df[s]['text'].to_list())\n",
    "    wd_list.extend(_df['text'].to_list())\n",
    "    wd_list = set(map(str.lower, wd_list))\n",
    "    return wd_list\n",
    "\n",
    "offensive_wd_list = get_offensive_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4964bae-e256-4389-88f1-2937754490b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_phrases(tokens, phrases):\n",
    "    tokens = list(map(str.lower, tokens))\n",
    "    \"\"\"\n",
    "    Find phrases in a list of sequential tokens.\n",
    "    \n",
    "    Args:\n",
    "        tokens (list): List of sequential tokens.\n",
    "        phrases (list): List of phrases to search for.\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the start and end index of each found phrase.\n",
    "    \"\"\"\n",
    "    found_phrases = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        for phrase in phrases:\n",
    "            if tokens[i:i+len(phrase)] == phrase:\n",
    "                found_phrases.append((i, i+len(phrase)-1))\n",
    "    \n",
    "    return found_phrases\n",
    "\n",
    "def offensive_lexicon_used(t):\n",
    "    tk = TweetTokenizer()\n",
    "    detk = mosestokenizer.MosesDetokenizer('en')\n",
    "    tk = tk.tokenize(t)\n",
    "    # print(tk)\n",
    "    phrase_index = find_phrases(tk, list(map(str.split, offensive_wd_list)))\n",
    "    return len(phrase_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9655ac19-9e57-493a-8118-129c493e66a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_counterfactual_tweets(data, labels, cf_label, single_cf_per_tweet=False, cf_size_prop_to_data=1.0, only_tweets_with_offensive_lexicon=True):\n",
    "    tweets = []\n",
    "    cnt =0 \n",
    "    for idx in data.index:\n",
    "        if idx in gpt_counterfactual_tweets:\n",
    "            if (not only_tweets_with_offensive_lexicon) or offensive_lexicon_used(X[idx]):\n",
    "                cnt += 1\n",
    "                if not single_cf_per_tweet:\n",
    "                    tweets.extend(gpt_counterfactual_tweets[idx])\n",
    "                else:\n",
    "                    tweets.append(gpt_counterfactual_tweets[idx][0])\n",
    "    print('> Total Tweets used to generate counterfactuals ' + str(cnt))\n",
    "    print('> Total counterfactuals added ' + str(len(tweets)))\n",
    "    k = round(cf_size_prop_to_data * len(tweets))\n",
    "    \n",
    "    tweets = random.sample(tweets, k=k)\n",
    "    print('> Counterfactual size ' + str(k) + ' at rate ' + str(cf_size_prop_to_data))\n",
    "    cf_target = k*[cf_label]\n",
    "    return pd.concat([data, pd.Series(tweets)], axis=0), pd.concat([labels, pd.Series(cf_target)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f96b6b9-79e2-4a75-a85e-0eb9d264133c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# winner tpot-pipeline 40\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88d17bd2-4227-44dc-819d-e353a92ba7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "only_tweets_with_offensive_lexicon = False\n",
    "\n",
    "def __exp__(pipeline, _x_train, _x_test, _y_train, _y_test, CF=False):\n",
    "    f = Features()\n",
    "    training_features = f.get_features(_x_train, isTrain=True)\n",
    "    testing_features = f.get_features(_x_test, isTrain=False)\n",
    "    \n",
    "    if not CF:\n",
    "        print('> Train samples', _x_train.shape[0])\n",
    "    else:\n",
    "        print('> Train with CF samples', _x_train.shape[0])\n",
    "    \n",
    "    try:\n",
    "        # Fix random state for all the steps in exported pipeline\n",
    "        set_param_recursive(pipeline.steps, 'random_state', 42)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    pipeline.fit(training_features, _y_train)\n",
    "    results = pipeline.predict(testing_features)\n",
    "\n",
    "    # report = classification_report(_y_test, results)\n",
    "    # print(report)\n",
    "    acc = accuracy_score(_y_test, results)\n",
    "    f1_marco = f1_score(_y_test, results, average='macro')\n",
    "    f1_weighted = f1_score(_y_test, results, average='weighted')\n",
    "    f1_non_avg = f1_score(_y_test, results, average=None)\n",
    "    r = {'Accuracy': acc,\n",
    "         'F1-Macro': f1_marco,\n",
    "         'F1-Weighted': f1_weighted,\n",
    "         'F1_Class 0': f1_non_avg[0],\n",
    "         'F1_Class 1': f1_non_avg[1],\n",
    "         'F1_Class 1': f1_non_avg[2],\n",
    "        }\n",
    "    print(r)\n",
    "    return [r]\n",
    "\n",
    "def run_experiment(pipeline, test_size_list=[0.95], cf_size_prop_to_data=0.1):\n",
    "    out_lst = []\n",
    "    for test_size in test_size_list:\n",
    "        print('Test size', test_size)\n",
    "        x_train, x_test, training_target, testing_target = \\\n",
    "                    train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        org = __exp__(pipeline, x_train, x_test, training_target, testing_target, CF=False)\n",
    "\n",
    "        x_train_with_cf, training_with_cf_target = get_counterfactual_tweets(\n",
    "            x_train, training_target, cf_label=CF_LABEL, single_cf_per_tweet=True, cf_size_prop_to_data=cf_size_prop_to_data, only_tweets_with_offensive_lexicon=only_tweets_with_offensive_lexicon)\n",
    "\n",
    "        cf = __exp__(pipeline, x_train_with_cf, x_test, training_with_cf_target, testing_target , CF=True)\n",
    "        l = [('test_size', test_size, len(x_test)),  ('train', len(x_train), len(x_train_with_cf)), {'Org': org, 'CF': cf}]\n",
    "        out_lst.append(l)\n",
    "    return out_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7d6915d-0eaf-44e3-9e27-6d206d6dcac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender (9454, 4)\n",
      "> Total Tweets used to generate counterfactuals 1612\n",
      "> Total counterfactuals added 1612\n",
      "> Counterfactual size 161 at rate 0.1\n",
      "Religion (10869, 4)\n",
      "> Total Tweets used to generate counterfactuals 1533\n",
      "> Total counterfactuals added 1533\n",
      "> Counterfactual size 153 at rate 0.1\n",
      "Race (12013, 4)\n",
      "> Total Tweets used to generate counterfactuals 1090\n",
      "> Total counterfactuals added 1090\n",
      "> Counterfactual size 109 at rate 0.1\n",
      "Politics (11018, 4)\n",
      "> Total Tweets used to generate counterfactuals 2041\n",
      "> Total counterfactuals added 2041\n",
      "> Counterfactual size 204 at rate 0.1\n",
      "Sports (12306, 4)\n",
      "> Total Tweets used to generate counterfactuals 1859\n",
      "> Total counterfactuals added 1859\n",
      "> Counterfactual size 186 at rate 0.1\n"
     ]
    }
   ],
   "source": [
    "for d in domains:\n",
    "    sel_df = df[df['Domain'] == d]\n",
    "    print(d, sel_df.shape)\n",
    "    X, y = sel_df['Tweet'], sel_df['Label'].astype(int)\n",
    "    _,_ = get_counterfactual_tweets(\n",
    "            X, y, cf_label=CF_LABEL, single_cf_per_tweet=True, cf_size_prop_to_data=.1, only_tweets_with_offensive_lexicon=only_tweets_with_offensive_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76a24f-77b9-4240-a1c8-1f2e5d710f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "960d5457-796b-4789-bbb2-236404c99470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_size_list = list(np.arange(0.1, 1.0, 0.1))\n",
    "cf_size_prop_to_data = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49dd3e6c-c187-4c0f-b9ca-bf5b6e1d9dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender (9454, 4)\n",
      "Test size 0.1\n",
      "> Train samples 8508\n",
      "{'Accuracy': 0.912262156448203, 'F1-Macro': 0.6300345469246273, 'F1-Weighted': 0.904591248815271, 'F1_Class 0': 0.9463806970509383, 'F1_Class 1': 0.13333333333333333}\n",
      "> Total Tweets used to generate counterfactuals 1463\n",
      "> Total counterfactuals added 1463\n",
      "> Counterfactual size 439 at rate 0.3\n",
      "> Train with CF samples 8947\n",
      "{'Accuracy': 0.9207188160676533, 'F1-Macro': 0.6390175097838592, 'F1-Weighted': 0.9133886551365981, 'F1_Class 0': 0.9516778523489934, 'F1_Class 1': 0.13333333333333333}\n",
      "Test size 0.2\n",
      "> Train samples 7563\n",
      "{'Accuracy': 0.9190904283447912, 'F1-Macro': 0.6139226153520857, 'F1-Weighted': 0.9117052078962714, 'F1_Class 0': 0.9523489932885907, 'F1_Class 1': 0.06451612903225806}\n",
      "> Total Tweets used to generate counterfactuals 1300\n",
      "> Total counterfactuals added 1300\n",
      "> Counterfactual size 390 at rate 0.3\n",
      "> Train with CF samples 7953\n",
      "{'Accuracy': 0.9159175039661555, 'F1-Macro': 0.6102495614755438, 'F1-Weighted': 0.9091201691873186, 'F1_Class 0': 0.9505549949545913, 'F1_Class 1': 0.06060606060606061}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 6617\n",
      "{'Accuracy': 0.913993655269651, 'F1-Macro': 0.6177374153378642, 'F1-Weighted': 0.9070838748988057, 'F1_Class 0': 0.9479377958079784, 'F1_Class 1': 0.0851063829787234}\n",
      "> Total Tweets used to generate counterfactuals 1123\n",
      "> Total counterfactuals added 1123\n",
      "> Counterfactual size 337 at rate 0.3\n",
      "> Train with CF samples 6954\n",
      "{'Accuracy': 0.9157560803665844, 'F1-Macro': 0.621866409724407, 'F1-Weighted': 0.9085310353486331, 'F1_Class 0': 0.9485559566787004, 'F1_Class 1': 0.09302325581395349}\n",
      "Test size 0.4\n",
      "> Train samples 5672\n",
      "{'Accuracy': 0.9058699101004759, 'F1-Macro': 0.6204702393838859, 'F1-Weighted': 0.8976462078767895, 'F1_Class 0': 0.9435238417314846, 'F1_Class 1': 0.11940298507462686}\n",
      "> Total Tweets used to generate counterfactuals 960\n",
      "> Total counterfactuals added 960\n",
      "> Counterfactual size 288 at rate 0.3\n",
      "> Train with CF samples 5960\n",
      "{'Accuracy': 0.9087784241142253, 'F1-Macro': 0.6036818632374777, 'F1-Weighted': 0.8996671536814123, 'F1_Class 0': 0.9455770850884582, 'F1_Class 1': 0.06060606060606061}\n",
      "Test size 0.5\n",
      "> Train samples 4727\n",
      "{'Accuracy': 0.9100909667865453, 'F1-Macro': 0.6140372706873883, 'F1-Weighted': 0.9012973483404455, 'F1_Class 0': 0.9467629748528625, 'F1_Class 1': 0.09302325581395349}\n",
      "> Total Tweets used to generate counterfactuals 825\n",
      "> Total counterfactuals added 825\n",
      "> Counterfactual size 248 at rate 0.3\n",
      "> Train with CF samples 4975\n",
      "{'Accuracy': 0.9045906494605458, 'F1-Macro': 0.6153983413787429, 'F1-Weighted': 0.8963945059133717, 'F1_Class 0': 0.9432595573440644, 'F1_Class 1': 0.11235955056179776}\n",
      "Test size 0.6\n",
      "> Train samples 3781\n",
      "{'Accuracy': 0.9051648157941125, 'F1-Macro': 0.5993370600120363, 'F1-Weighted': 0.8959929794400292, 'F1_Class 0': 0.9433202906651761, 'F1_Class 1': 0.0625}\n",
      "> Total Tweets used to generate counterfactuals 655\n",
      "> Total counterfactuals added 655\n",
      "> Counterfactual size 196 at rate 0.3\n",
      "> Train with CF samples 3977\n",
      "{'Accuracy': 0.9051648157941125, 'F1-Macro': 0.617836200933472, 'F1-Weighted': 0.8972042836116053, 'F1_Class 0': 0.9433666031176404, 'F1_Class 1': 0.11650485436893204}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 2836\n",
      "{'Accuracy': 0.8921124206708976, 'F1-Macro': 0.6007608286923244, 'F1-Weighted': 0.8835330318257614, 'F1_Class 0': 0.9341571731994593, 'F1_Class 1': 0.09917355371900825}\n",
      "> Total Tweets used to generate counterfactuals 488\n",
      "> Total counterfactuals added 488\n",
      "> Counterfactual size 146 at rate 0.3\n",
      "> Train with CF samples 2982\n",
      "{'Accuracy': 0.8983076458144454, 'F1-Macro': 0.5960215256811342, 'F1-Weighted': 0.8889527246156068, 'F1_Class 0': 0.9383238718368133, 'F1_Class 1': 0.06837606837606837}\n",
      "Test size 0.8\n",
      "> Train samples 1890\n",
      "{'Accuracy': 0.8927815970386039, 'F1-Macro': 0.584865543104144, 'F1-Weighted': 0.8843047890668893, 'F1_Class 0': 0.9346699515759068, 'F1_Class 1': 0.04511278195488722}\n",
      "> Total Tweets used to generate counterfactuals 317\n",
      "> Total counterfactuals added 317\n",
      "> Counterfactual size 95 at rate 0.3\n",
      "> Train with CF samples 1985\n",
      "{'Accuracy': 0.8995240613432046, 'F1-Macro': 0.5897264828993499, 'F1-Weighted': 0.8904157689186131, 'F1_Class 0': 0.9393709419006661, 'F1_Class 1': 0.04347826086956521}\n",
      "Test size 0.9\n",
      "> Train samples 945\n",
      "{'Accuracy': 0.8804794923022682, 'F1-Macro': 0.5528241366618856, 'F1-Weighted': 0.868508043322438, 'F1_Class 0': 0.9275792913912204, 'F1_Class 1': 0.0}\n",
      "> Total Tweets used to generate counterfactuals 140\n",
      "> Total counterfactuals added 140\n",
      "> Counterfactual size 42 at rate 0.3\n",
      "> Train with CF samples 987\n",
      "{'Accuracy': 0.8781290398401692, 'F1-Macro': 0.5522184350268436, 'F1-Weighted': 0.8674667435982342, 'F1_Class 0': 0.9263959390862945, 'F1_Class 1': 0.0}\n",
      "Religion (10869, 4)\n",
      "Test size 0.1\n",
      "> Train samples 9782\n",
      "{'Accuracy': 0.9006439742410304, 'F1-Macro': 0.6180204265897445, 'F1-Weighted': 0.8901252547358267, 'F1_Class 0': 0.9443838604143947, 'F1_Class 1': 0.19999999999999998}\n",
      "> Total Tweets used to generate counterfactuals 1385\n",
      "> Total counterfactuals added 1385\n",
      "> Counterfactual size 416 at rate 0.3\n",
      "> Train with CF samples 10198\n",
      "{'Accuracy': 0.8997240110395585, 'F1-Macro': 0.6350327625550686, 'F1-Weighted': 0.8899682985631668, 'F1_Class 0': 0.9438079650845608, 'F1_Class 1': 0.25806451612903225}\n",
      "Test size 0.2\n",
      "> Train samples 8695\n",
      "{'Accuracy': 0.9043238270469182, 'F1-Macro': 0.6053292618516767, 'F1-Weighted': 0.8950271967155089, 'F1_Class 0': 0.9469945355191257, 'F1_Class 1': 0.14545454545454545}\n",
      "> Total Tweets used to generate counterfactuals 1235\n",
      "> Total counterfactuals added 1235\n",
      "> Counterfactual size 370 at rate 0.3\n",
      "> Train with CF samples 9065\n",
      "{'Accuracy': 0.9043238270469182, 'F1-Macro': 0.6049915528616345, 'F1-Weighted': 0.8945688168020046, 'F1_Class 0': 0.9470812875068193, 'F1_Class 1': 0.14814814814814814}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 7608\n",
      "{'Accuracy': 0.9101502606562404, 'F1-Macro': 0.6334141645777703, 'F1-Weighted': 0.9008912709941668, 'F1_Class 0': 0.9495828799419659, 'F1_Class 1': 0.2117647058823529}\n",
      "> Total Tweets used to generate counterfactuals 1085\n",
      "> Total counterfactuals added 1085\n",
      "> Counterfactual size 326 at rate 0.3\n",
      "> Train with CF samples 7934\n",
      "{'Accuracy': 0.9076970254523152, 'F1-Macro': 0.6453289866042756, 'F1-Weighted': 0.8983579877604968, 'F1_Class 0': 0.9483381502890174, 'F1_Class 1': 0.26666666666666666}\n",
      "Test size 0.4\n",
      "> Train samples 6521\n",
      "{'Accuracy': 0.9024839006439742, 'F1-Macro': 0.6192896969869781, 'F1-Weighted': 0.894094679775368, 'F1_Class 0': 0.9451453647833242, 'F1_Class 1': 0.18644067796610167}\n",
      "> Total Tweets used to generate counterfactuals 938\n",
      "> Total counterfactuals added 938\n",
      "> Counterfactual size 281 at rate 0.3\n",
      "> Train with CF samples 6802\n",
      "{'Accuracy': 0.9043238270469182, 'F1-Macro': 0.5921630301742391, 'F1-Weighted': 0.8922840942754099, 'F1_Class 0': 0.9461986719067625, 'F1_Class 1': 0.11009174311926605}\n",
      "Test size 0.5\n",
      "> Train samples 5434\n",
      "{'Accuracy': 0.909475620975161, 'F1-Macro': 0.6251348473305258, 'F1-Weighted': 0.9003376336804616, 'F1_Class 0': 0.948636512977768, 'F1_Class 1': 0.17910447761194032}\n",
      "> Total Tweets used to generate counterfactuals 777\n",
      "> Total counterfactuals added 777\n",
      "> Counterfactual size 233 at rate 0.3\n",
      "> Train with CF samples 5667\n",
      "{'Accuracy': 0.906163753449862, 'F1-Macro': 0.6150491211841871, 'F1-Weighted': 0.8966863170237677, 'F1_Class 0': 0.9465281574630946, 'F1_Class 1': 0.16058394160583941}\n",
      "Test size 0.6\n",
      "> Train samples 4347\n",
      "{'Accuracy': 0.9069303894510886, 'F1-Macro': 0.6291136711207551, 'F1-Weighted': 0.8986093419044249, 'F1_Class 0': 0.9473492106944065, 'F1_Class 1': 0.2023809523809524}\n",
      "> Total Tweets used to generate counterfactuals 632\n",
      "> Total counterfactuals added 632\n",
      "> Counterfactual size 190 at rate 0.3\n",
      "> Train with CF samples 4537\n",
      "{'Accuracy': 0.9024839006439742, 'F1-Macro': 0.6055546785967607, 'F1-Weighted': 0.8915979989379508, 'F1_Class 0': 0.9447508816348675, 'F1_Class 1': 0.15950920245398773}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3260\n",
      "{'Accuracy': 0.9080036798528058, 'F1-Macro': 0.6302687347208743, 'F1-Weighted': 0.8990861197844363, 'F1_Class 0': 0.9481124747553208, 'F1_Class 1': 0.21390374331550802}\n",
      "> Total Tweets used to generate counterfactuals 504\n",
      "> Total counterfactuals added 504\n",
      "> Counterfactual size 151 at rate 0.3\n",
      "> Train with CF samples 3411\n",
      "{'Accuracy': 0.9089236430542779, 'F1-Macro': 0.6344199750602822, 'F1-Weighted': 0.9002039538377982, 'F1_Class 0': 0.9487975174553919, 'F1_Class 1': 0.22335025380710657}\n",
      "Test size 0.8\n",
      "> Train samples 2173\n",
      "{'Accuracy': 0.8976540938362465, 'F1-Macro': 0.596364968530492, 'F1-Weighted': 0.8877841691895542, 'F1_Class 0': 0.9420665212649945, 'F1_Class 1': 0.14778325123152708}\n",
      "> Total Tweets used to generate counterfactuals 338\n",
      "> Total counterfactuals added 338\n",
      "> Counterfactual size 101 at rate 0.3\n",
      "> Train with CF samples 2274\n",
      "{'Accuracy': 0.8944342226310947, 'F1-Macro': 0.5879255506653734, 'F1-Weighted': 0.8851378243171323, 'F1_Class 0': 0.9407103825136613, 'F1_Class 1': 0.13145539906103287}\n",
      "Test size 0.9\n",
      "> Train samples 1086\n",
      "{'Accuracy': 0.8803025656751507, 'F1-Macro': 0.5652118293238665, 'F1-Weighted': 0.8705769137927105, 'F1_Class 0': 0.9324012158054711, 'F1_Class 1': 0.11764705882352941}\n",
      "> Total Tweets used to generate counterfactuals 171\n",
      "> Total counterfactuals added 171\n",
      "> Counterfactual size 51 at rate 0.3\n",
      "> Train with CF samples 1137\n",
      "{'Accuracy': 0.8811203107431258, 'F1-Macro': 0.5647129916316564, 'F1-Weighted': 0.8714546178520134, 'F1_Class 0': 0.9327168755323032, 'F1_Class 1': 0.1111111111111111}\n",
      "Race (12013, 4)\n",
      "Test size 0.1\n",
      "> Train samples 10811\n",
      "{'Accuracy': 0.9151414309484193, 'F1-Macro': 0.6032848341835227, 'F1-Weighted': 0.9043844546726963, 'F1_Class 0': 0.9564411492122336, 'F1_Class 1': 0.25806451612903225}\n",
      "> Total Tweets used to generate counterfactuals 982\n",
      "> Total counterfactuals added 982\n",
      "> Counterfactual size 295 at rate 0.3\n",
      "> Train with CF samples 11106\n",
      "{'Accuracy': 0.913477537437604, 'F1-Macro': 0.5688424582177968, 'F1-Weighted': 0.8969244029403965, 'F1_Class 0': 0.9551282051282052, 'F1_Class 1': 0.20689655172413793}\n",
      "Test size 0.2\n",
      "> Train samples 9610\n",
      "{'Accuracy': 0.9192675821889305, 'F1-Macro': 0.6087557603686636, 'F1-Weighted': 0.9088249902675419, 'F1_Class 0': 0.9599078341013826, 'F1_Class 1': 0.2857142857142857}\n",
      "> Total Tweets used to generate counterfactuals 882\n",
      "> Total counterfactuals added 882\n",
      "> Counterfactual size 265 at rate 0.3\n",
      "> Train with CF samples 9875\n",
      "{'Accuracy': 0.916354556803995, 'F1-Macro': 0.6108108390630677, 'F1-Weighted': 0.9063233440396169, 'F1_Class 0': 0.9568627450980393, 'F1_Class 1': 0.2950819672131148}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 8409\n",
      "{'Accuracy': 0.9173140954495006, 'F1-Macro': 0.6242119532561986, 'F1-Weighted': 0.9067078861335243, 'F1_Class 0': 0.9578850292038119, 'F1_Class 1': 0.33999999999999997}\n",
      "> Total Tweets used to generate counterfactuals 770\n",
      "> Total counterfactuals added 770\n",
      "> Counterfactual size 231 at rate 0.3\n",
      "> Train with CF samples 8640\n",
      "{'Accuracy': 0.9173140954495006, 'F1-Macro': 0.6153850741710921, 'F1-Weighted': 0.9053623534821799, 'F1_Class 0': 0.9578544061302682, 'F1_Class 1': 0.32323232323232326}\n",
      "Test size 0.4\n",
      "> Train samples 7207\n",
      "{'Accuracy': 0.9178110694964627, 'F1-Macro': 0.6480651731812358, 'F1-Weighted': 0.909620177479961, 'F1_Class 0': 0.9584011155008134, 'F1_Class 1': 0.3815789473684211}\n",
      "> Total Tweets used to generate counterfactuals 651\n",
      "> Total counterfactuals added 651\n",
      "> Counterfactual size 195 at rate 0.3\n",
      "> Train with CF samples 7402\n",
      "{'Accuracy': 0.9178110694964627, 'F1-Macro': 0.6228739463026675, 'F1-Weighted': 0.9077321162805362, 'F1_Class 0': 0.9587772116720704, 'F1_Class 1': 0.31081081081081086}\n",
      "Test size 0.5\n",
      "> Train samples 6006\n",
      "{'Accuracy': 0.9149325786582321, 'F1-Macro': 0.6298394137213436, 'F1-Weighted': 0.9065437849835133, 'F1_Class 0': 0.9571215510812826, 'F1_Class 1': 0.33149171270718236}\n",
      "> Total Tweets used to generate counterfactuals 542\n",
      "> Total counterfactuals added 542\n",
      "> Counterfactual size 163 at rate 0.3\n",
      "> Train with CF samples 6169\n",
      "{'Accuracy': 0.9106042949891793, 'F1-Macro': 0.6167198344844094, 'F1-Weighted': 0.9016549967363561, 'F1_Class 0': 0.954465033988267, 'F1_Class 1': 0.31693989071038253}\n",
      "Test size 0.6\n",
      "> Train samples 4805\n",
      "{'Accuracy': 0.9146781354051055, 'F1-Macro': 0.6272812499340438, 'F1-Weighted': 0.9044768459956333, 'F1_Class 0': 0.9570666047806915, 'F1_Class 1': 0.3389830508474576}\n",
      "> Total Tweets used to generate counterfactuals 417\n",
      "> Total counterfactuals added 417\n",
      "> Counterfactual size 125 at rate 0.3\n",
      "> Train with CF samples 4930\n",
      "{'Accuracy': 0.9085738068812431, 'F1-Macro': 0.6024348196174036, 'F1-Weighted': 0.8978113963137223, 'F1_Class 0': 0.9540176497909894, 'F1_Class 1': 0.296943231441048}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3603\n",
      "{'Accuracy': 0.9072532699167658, 'F1-Macro': 0.5822112689209017, 'F1-Weighted': 0.8959658400606701, 'F1_Class 0': 0.9530805373568924, 'F1_Class 1': 0.24521072796934865}\n",
      "> Total Tweets used to generate counterfactuals 326\n",
      "> Total counterfactuals added 326\n",
      "> Counterfactual size 98 at rate 0.3\n",
      "> Train with CF samples 3701\n",
      "{'Accuracy': 0.9084423305588585, 'F1-Macro': 0.6034058694348788, 'F1-Weighted': 0.8991645384772339, 'F1_Class 0': 0.9539748953974896, 'F1_Class 1': 0.29629629629629634}\n",
      "Test size 0.8\n",
      "> Train samples 2402\n",
      "{'Accuracy': 0.9044844449068775, 'F1-Macro': 0.59562400030099, 'F1-Weighted': 0.8935979879224234, 'F1_Class 0': 0.9509070886222686, 'F1_Class 1': 0.3026315789473684}\n",
      "> Total Tweets used to generate counterfactuals 205\n",
      "> Total counterfactuals added 205\n",
      "> Counterfactual size 62 at rate 0.3\n",
      "> Train with CF samples 2464\n",
      "{'Accuracy': 0.908646342732286, 'F1-Macro': 0.5750384629287683, 'F1-Weighted': 0.8951665920756617, 'F1_Class 0': 0.9537875728379391, 'F1_Class 1': 0.22916666666666666}\n",
      "Test size 0.9\n",
      "> Train samples 1201\n",
      "{'Accuracy': 0.8976137624861266, 'F1-Macro': 0.5343368989708953, 'F1-Weighted': 0.8813521359332547, 'F1_Class 0': 0.9478634226129626, 'F1_Class 1': 0.19254658385093165}\n",
      "> Total Tweets used to generate counterfactuals 104\n",
      "> Total counterfactuals added 104\n",
      "> Counterfactual size 31 at rate 0.3\n",
      "> Train with CF samples 1232\n",
      "{'Accuracy': 0.896503884572697, 'F1-Macro': 0.5361760789413443, 'F1-Weighted': 0.88052643494886, 'F1_Class 0': 0.9468139511097473, 'F1_Class 1': 0.2}\n",
      "Politics (11018, 4)\n",
      "Test size 0.1\n",
      "> Train samples 9916\n",
      "{'Accuracy': 0.8983666061705989, 'F1-Macro': 0.6496301692613885, 'F1-Weighted': 0.8886289557977659, 'F1_Class 0': 0.9429747207524986, 'F1_Class 1': 0.21621621621621623}\n",
      "> Total Tweets used to generate counterfactuals 1838\n",
      "> Total counterfactuals added 1838\n",
      "> Counterfactual size 551 at rate 0.3\n",
      "> Train with CF samples 10467\n",
      "{'Accuracy': 0.9010889292196007, 'F1-Macro': 0.6368392827216357, 'F1-Weighted': 0.8905441452489601, 'F1_Class 0': 0.9447058823529412, 'F1_Class 1': 0.16666666666666666}\n",
      "Test size 0.2\n",
      "> Train samples 8814\n",
      "{'Accuracy': 0.9097096188747731, 'F1-Macro': 0.6588998868497716, 'F1-Weighted': 0.9000271866322759, 'F1_Class 0': 0.9517402749341913, 'F1_Class 1': 0.2162162162162162}\n",
      "> Total Tweets used to generate counterfactuals 1636\n",
      "> Total counterfactuals added 1636\n",
      "> Counterfactual size 491 at rate 0.3\n",
      "> Train with CF samples 9305\n",
      "{'Accuracy': 0.9097096188747731, 'F1-Macro': 0.649127822325552, 'F1-Weighted': 0.9002489530069149, 'F1_Class 0': 0.9527720739219713, 'F1_Class 1': 0.1842105263157895}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 7712\n",
      "{'Accuracy': 0.9074410163339383, 'F1-Macro': 0.6562361939749465, 'F1-Weighted': 0.8971490640126429, 'F1_Class 0': 0.9479859210011734, 'F1_Class 1': 0.20952380952380953}\n",
      "> Total Tweets used to generate counterfactuals 1400\n",
      "> Total counterfactuals added 1400\n",
      "> Counterfactual size 420 at rate 0.3\n",
      "> Train with CF samples 8132\n",
      "{'Accuracy': 0.9077434966727163, 'F1-Macro': 0.6660028044407101, 'F1-Weighted': 0.8979659055274646, 'F1_Class 0': 0.9478821003318367, 'F1_Class 1': 0.2385321100917431}\n",
      "Test size 0.4\n",
      "> Train samples 6610\n",
      "{'Accuracy': 0.9108439201451906, 'F1-Macro': 0.6678747711174142, 'F1-Weighted': 0.9027214809932228, 'F1_Class 0': 0.9499417927823051, 'F1_Class 1': 0.2424242424242424}\n",
      "> Total Tweets used to generate counterfactuals 1219\n",
      "> Total counterfactuals added 1219\n",
      "> Counterfactual size 366 at rate 0.3\n",
      "> Train with CF samples 6976\n",
      "{'Accuracy': 0.9117513611615246, 'F1-Macro': 0.6621642508576121, 'F1-Weighted': 0.9025819532914499, 'F1_Class 0': 0.9499927525728367, 'F1_Class 1': 0.22399999999999998}\n",
      "Test size 0.5\n",
      "> Train samples 5509\n",
      "{'Accuracy': 0.9036122708295516, 'F1-Macro': 0.6535751806682345, 'F1-Weighted': 0.895257661227153, 'F1_Class 0': 0.9447610187231072, 'F1_Class 1': 0.2195121951219512}\n",
      "> Total Tweets used to generate counterfactuals 1014\n",
      "> Total counterfactuals added 1014\n",
      "> Counterfactual size 304 at rate 0.3\n",
      "> Train with CF samples 5813\n",
      "{'Accuracy': 0.9019785805046288, 'F1-Macro': 0.6501789159669437, 'F1-Weighted': 0.8928634888222441, 'F1_Class 0': 0.9435008665511264, 'F1_Class 1': 0.21686746987951808}\n",
      "Test size 0.6\n",
      "> Train samples 4407\n",
      "{'Accuracy': 0.906065648162154, 'F1-Macro': 0.6721157142395136, 'F1-Weighted': 0.8986400219361502, 'F1_Class 0': 0.9463471427185407, 'F1_Class 1': 0.27}\n",
      "> Total Tweets used to generate counterfactuals 818\n",
      "> Total counterfactuals added 818\n",
      "> Counterfactual size 245 at rate 0.3\n",
      "> Train with CF samples 4652\n",
      "{'Accuracy': 0.9050068068370897, 'F1-Macro': 0.6715520303550343, 'F1-Weighted': 0.8971967923464159, 'F1_Class 0': 0.945995555984929, 'F1_Class 1': 0.27450980392156865}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3305\n",
      "{'Accuracy': 0.9006871515622974, 'F1-Macro': 0.6452887000412303, 'F1-Weighted': 0.8914213041985672, 'F1_Class 0': 0.9437774281692473, 'F1_Class 1': 0.2090909090909091}\n",
      "> Total Tweets used to generate counterfactuals 601\n",
      "> Total counterfactuals added 601\n",
      "> Counterfactual size 180 at rate 0.3\n",
      "> Train with CF samples 3485\n",
      "{'Accuracy': 0.9018540127058213, 'F1-Macro': 0.64854923559271, 'F1-Weighted': 0.8924964470487559, 'F1_Class 0': 0.9443847615899513, 'F1_Class 1': 0.21621621621621623}\n",
      "Test size 0.8\n",
      "> Train samples 2203\n",
      "{'Accuracy': 0.8967668746454907, 'F1-Macro': 0.6197021525065848, 'F1-Weighted': 0.8866483065255423, 'F1_Class 0': 0.9413808076422058, 'F1_Class 1': 0.14345991561181434}\n",
      "> Total Tweets used to generate counterfactuals 409\n",
      "> Total counterfactuals added 409\n",
      "> Counterfactual size 123 at rate 0.3\n",
      "> Train with CF samples 2326\n",
      "{'Accuracy': 0.8980147475893363, 'F1-Macro': 0.6144481402944205, 'F1-Weighted': 0.886707024802656, 'F1_Class 0': 0.9425386551600143, 'F1_Class 1': 0.12875536480686697}\n",
      "Test size 0.9\n",
      "> Train samples 1101\n",
      "{'Accuracy': 0.860139154986387, 'F1-Macro': 0.5871217971881647, 'F1-Weighted': 0.8519689418336125, 'F1_Class 0': 0.9189294277752577, 'F1_Class 1': 0.14814814814814814}\n",
      "> Total Tweets used to generate counterfactuals 195\n",
      "> Total counterfactuals added 195\n",
      "> Counterfactual size 58 at rate 0.3\n",
      "> Train with CF samples 1159\n",
      "{'Accuracy': 0.868407784612282, 'F1-Macro': 0.5784706448460816, 'F1-Weighted': 0.8559539156977028, 'F1_Class 0': 0.924506683640993, 'F1_Class 1': 0.11409395973154361}\n",
      "Sports (12306, 4)\n",
      "Test size 0.1\n",
      "> Train samples 11075\n",
      "{'Accuracy': 0.9390739236393176, 'F1-Macro': 0.69260663507109, 'F1-Weighted': 0.9325871156267204, 'F1_Class 0': 0.97, 'F1_Class 1': 0.25}\n",
      "> Total Tweets used to generate counterfactuals 1674\n",
      "> Total counterfactuals added 1674\n",
      "> Counterfactual size 502 at rate 0.3\n",
      "> Train with CF samples 11577\n",
      "{'Accuracy': 0.942323314378554, 'F1-Macro': 0.7106882136366077, 'F1-Weighted': 0.9365803806621609, 'F1_Class 0': 0.971457185778668, 'F1_Class 1': 0.29268292682926833}\n",
      "Test size 0.2\n",
      "> Train samples 9844\n",
      "{'Accuracy': 0.938667749796913, 'F1-Macro': 0.6931934661084488, 'F1-Weighted': 0.9324282243677375, 'F1_Class 0': 0.9692385274836107, 'F1_Class 1': 0.2535211267605634}\n",
      "> Total Tweets used to generate counterfactuals 1467\n",
      "> Total counterfactuals added 1467\n",
      "> Counterfactual size 440 at rate 0.3\n",
      "> Train with CF samples 10284\n",
      "{'Accuracy': 0.9329813160032494, 'F1-Macro': 0.6732881104762614, 'F1-Weighted': 0.9246145896417076, 'F1_Class 0': 0.9652586853286678, 'F1_Class 1': 0.21874999999999994}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 8614\n",
      "{'Accuracy': 0.94068255687974, 'F1-Macro': 0.703632289409346, 'F1-Weighted': 0.9361274679537596, 'F1_Class 0': 0.9704950825137523, 'F1_Class 1': 0.28571428571428575}\n",
      "> Total Tweets used to generate counterfactuals 1302\n",
      "> Total counterfactuals added 1302\n",
      "> Counterfactual size 391 at rate 0.3\n",
      "> Train with CF samples 9005\n",
      "{'Accuracy': 0.9431202600216685, 'F1-Macro': 0.70590392366449, 'F1-Weighted': 0.9379855372473737, 'F1_Class 0': 0.9715142428785607, 'F1_Class 1': 0.2857142857142857}\n",
      "Test size 0.4\n",
      "> Train samples 7383\n",
      "{'Accuracy': 0.9441397521836279, 'F1-Macro': 0.6983372759939775, 'F1-Weighted': 0.9395123800899245, 'F1_Class 0': 0.9718274744452755, 'F1_Class 1': 0.26016260162601623}\n",
      "> Total Tweets used to generate counterfactuals 1124\n",
      "> Total counterfactuals added 1124\n",
      "> Counterfactual size 337 at rate 0.3\n",
      "> Train with CF samples 7720\n",
      "{'Accuracy': 0.9451553930530164, 'F1-Macro': 0.701210040489593, 'F1-Weighted': 0.9403949325565152, 'F1_Class 0': 0.9724473257698542, 'F1_Class 1': 0.26666666666666666}\n",
      "Test size 0.5\n",
      "> Train samples 6153\n",
      "{'Accuracy': 0.9457175361612221, 'F1-Macro': 0.6662402580762613, 'F1-Weighted': 0.940010960001359, 'F1_Class 0': 0.9726190476190475, 'F1_Class 1': 0.16393442622950824}\n",
      "> Total Tweets used to generate counterfactuals 963\n",
      "> Total counterfactuals added 963\n",
      "> Counterfactual size 289 at rate 0.3\n",
      "> Train with CF samples 6442\n",
      "{'Accuracy': 0.9475052819762717, 'F1-Macro': 0.6837130583848733, 'F1-Weighted': 0.9428236986864791, 'F1_Class 0': 0.9742621484646725, 'F1_Class 1': 0.21052631578947364}\n",
      "Test size 0.6\n",
      "> Train samples 4922\n",
      "{'Accuracy': 0.9414951245937161, 'F1-Macro': 0.653791711887474, 'F1-Weighted': 0.9349714107775355, 'F1_Class 0': 0.969786778628468, 'F1_Class 1': 0.14388489208633096}\n",
      "> Total Tweets used to generate counterfactuals 785\n",
      "> Total counterfactuals added 785\n",
      "> Counterfactual size 236 at rate 0.3\n",
      "> Train with CF samples 5158\n",
      "{'Accuracy': 0.9439328277356447, 'F1-Macro': 0.6728531269345619, 'F1-Weighted': 0.9394726278669518, 'F1_Class 0': 0.9714001492166129, 'F1_Class 1': 0.18518518518518523}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3691\n",
      "{'Accuracy': 0.943006384213581, 'F1-Macro': 0.6711103764817556, 'F1-Weighted': 0.9387295881652683, 'F1_Class 0': 0.9712255772646536, 'F1_Class 1': 0.18274111675126903}\n",
      "> Total Tweets used to generate counterfactuals 596\n",
      "> Total counterfactuals added 596\n",
      "> Counterfactual size 179 at rate 0.3\n",
      "> Train with CF samples 3870\n",
      "{'Accuracy': 0.943122460824144, 'F1-Macro': 0.6653835998639718, 'F1-Weighted': 0.9381442744930457, 'F1_Class 0': 0.9714690265486725, 'F1_Class 1': 0.16842105263157892}\n",
      "Test size 0.8\n",
      "> Train samples 2461\n",
      "{'Accuracy': 0.9337734890807516, 'F1-Macro': 0.6535306797066722, 'F1-Weighted': 0.9281406835217901, 'F1_Class 0': 0.9660269548475251, 'F1_Class 1': 0.1651376146788991}\n",
      "> Total Tweets used to generate counterfactuals 401\n",
      "> Total counterfactuals added 401\n",
      "> Counterfactual size 120 at rate 0.3\n",
      "> Train with CF samples 2581\n",
      "{'Accuracy': 0.9312341289994921, 'F1-Macro': 0.6761196238181161, 'F1-Weighted': 0.9270284710542506, 'F1_Class 0': 0.965406075635462, 'F1_Class 1': 0.24427480916030533}\n",
      "Test size 0.9\n",
      "> Train samples 1230\n",
      "{'Accuracy': 0.9244312026002167, 'F1-Macro': 0.6278540925981063, 'F1-Weighted': 0.9172566343760448, 'F1_Class 0': 0.9598986449267379, 'F1_Class 1': 0.12068965517241378}\n",
      "> Total Tweets used to generate counterfactuals 207\n",
      "> Total counterfactuals added 207\n",
      "> Counterfactual size 62 at rate 0.3\n",
      "> Train with CF samples 1292\n",
      "{'Accuracy': 0.9313831708197905, 'F1-Macro': 0.6287325303565795, 'F1-Weighted': 0.9232127536252938, 'F1_Class 0': 0.9636373608292657, 'F1_Class 1': 0.10138248847926266}\n"
     ]
    }
   ],
   "source": [
    "for d in domains:\n",
    "    sel_df = df[df['Domain'] == d]\n",
    "    print(d, sel_df.shape)\n",
    "    X, y = sel_df['Tweet'], sel_df['Label'].astype(int)\n",
    "\n",
    "    tpot_exported_pipeline = make_pipeline(\n",
    "        StackingEstimator(estimator=LinearSVC(C=15.0, dual=False, loss=\"squared_hinge\", penalty=\"l2\", tol=0.01)),\n",
    "        DecisionTreeClassifier(criterion=\"gini\", max_depth=3, min_samples_leaf=12, min_samples_split=3)\n",
    "    )\n",
    "    \n",
    "    res_tpot_lst = run_experiment(tpot_exported_pipeline, test_size_list=test_size_list, cf_size_prop_to_data=cf_size_prop_to_data)\n",
    "    json.dump(res_tpot_lst, open('out/tpot-lshd22-' + d + '.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d5bf872-5f39-4cf6-931d-b363e25d5b80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender (9454, 4)\n",
      "Test size 0.1\n",
      "> Train samples 8508\n",
      "{'Accuracy': 0.8974630021141649, 'F1-Macro': 0.6835141262925841, 'F1-Weighted': 0.9077358599067605, 'F1_Class 0': 0.9429175475687104, 'F1_Class 1': 0.2807017543859649}\n",
      "> Total Tweets used to generate counterfactuals 1463\n",
      "> Total counterfactuals added 1463\n",
      "> Counterfactual size 439 at rate 0.3\n",
      "> Train with CF samples 8947\n",
      "{'Accuracy': 0.8942917547568711, 'F1-Macro': 0.6606846205437754, 'F1-Weighted': 0.9051646437414534, 'F1_Class 0': 0.9408450704225352, 'F1_Class 1': 0.21428571428571427}\n",
      "Test size 0.2\n",
      "> Train samples 7563\n",
      "{'Accuracy': 0.8958223162347964, 'F1-Macro': 0.6775733504019575, 'F1-Weighted': 0.9083536210296442, 'F1_Class 0': 0.9421312632321805, 'F1_Class 1': 0.25806451612903225}\n",
      "> Total Tweets used to generate counterfactuals 1300\n",
      "> Total counterfactuals added 1300\n",
      "> Counterfactual size 390 at rate 0.3\n",
      "> Train with CF samples 7953\n",
      "{'Accuracy': 0.896351136964569, 'F1-Macro': 0.6867175602273624, 'F1-Weighted': 0.9077043481599465, 'F1_Class 0': 0.9403037795831861, 'F1_Class 1': 0.2857142857142857}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 6617\n",
      "{'Accuracy': 0.8819175185054635, 'F1-Macro': 0.6608694957298783, 'F1-Weighted': 0.8985610099383595, 'F1_Class 0': 0.9320943531093638, 'F1_Class 1': 0.22325581395348837}\n",
      "> Total Tweets used to generate counterfactuals 1123\n",
      "> Total counterfactuals added 1123\n",
      "> Counterfactual size 337 at rate 0.3\n",
      "> Train with CF samples 6954\n",
      "{'Accuracy': 0.8822700035248502, 'F1-Macro': 0.6550758248173558, 'F1-Weighted': 0.8980760257257681, 'F1_Class 0': 0.9316503929507024, 'F1_Class 1': 0.2058823529411765}\n",
      "Test size 0.4\n",
      "> Train samples 5672\n",
      "{'Accuracy': 0.8670015864621893, 'F1-Macro': 0.6472658755228917, 'F1-Weighted': 0.8864949627076052, 'F1_Class 0': 0.9217796914244707, 'F1_Class 1': 0.20359281437125748}\n",
      "> Total Tweets used to generate counterfactuals 960\n",
      "> Total counterfactuals added 960\n",
      "> Counterfactual size 288 at rate 0.3\n",
      "> Train with CF samples 5960\n",
      "{'Accuracy': 0.8714965626652564, 'F1-Macro': 0.6471351980001739, 'F1-Weighted': 0.8892937567021739, 'F1_Class 0': 0.9250313115047415, 'F1_Class 1': 0.19808306709265175}\n",
      "Test size 0.5\n",
      "> Train samples 4727\n",
      "{'Accuracy': 0.865453776179395, 'F1-Macro': 0.6369573948337379, 'F1-Weighted': 0.883427481792119, 'F1_Class 0': 0.920689164174854, 'F1_Class 1': 0.18508997429305915}\n",
      "> Total Tweets used to generate counterfactuals 825\n",
      "> Total counterfactuals added 825\n",
      "> Counterfactual size 248 at rate 0.3\n",
      "> Train with CF samples 4975\n",
      "{'Accuracy': 0.872858049502856, 'F1-Macro': 0.6403641338837532, 'F1-Weighted': 0.889958314019293, 'F1_Class 0': 0.9254155419803949, 'F1_Class 1': 0.17647058823529413}\n",
      "Test size 0.6\n",
      "> Train samples 3781\n",
      "{'Accuracy': 0.8605676009166225, 'F1-Macro': 0.6272243819471325, 'F1-Weighted': 0.8797652771182473, 'F1_Class 0': 0.9177870315288519, 'F1_Class 1': 0.16421052631578947}\n",
      "> Total Tweets used to generate counterfactuals 655\n",
      "> Total counterfactuals added 655\n",
      "> Counterfactual size 196 at rate 0.3\n",
      "> Train with CF samples 3977\n",
      "{'Accuracy': 0.8633879781420765, 'F1-Macro': 0.6270143319940423, 'F1-Weighted': 0.8812932838667499, 'F1_Class 0': 0.9190023752969122, 'F1_Class 1': 0.15929203539823011}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 2836\n",
      "{'Accuracy': 0.862496222423693, 'F1-Macro': 0.6291650341115532, 'F1-Weighted': 0.8773090333992094, 'F1_Class 0': 0.9184314520214814, 'F1_Class 1': 0.18036072144288579}\n",
      "> Total Tweets used to generate counterfactuals 488\n",
      "> Total counterfactuals added 488\n",
      "> Counterfactual size 146 at rate 0.3\n",
      "> Train with CF samples 2982\n",
      "{'Accuracy': 0.8626473254759747, 'F1-Macro': 0.630424270542771, 'F1-Weighted': 0.877027136037045, 'F1_Class 0': 0.9180461054128162, 'F1_Class 1': 0.18480492813141683}\n",
      "Test size 0.8\n",
      "> Train samples 1890\n",
      "{'Accuracy': 0.846641988365944, 'F1-Macro': 0.6090649113837721, 'F1-Weighted': 0.861846530278193, 'F1_Class 0': 0.9081262711115042, 'F1_Class 1': 0.163265306122449}\n",
      "> Total Tweets used to generate counterfactuals 317\n",
      "> Total counterfactuals added 317\n",
      "> Counterfactual size 95 at rate 0.3\n",
      "> Train with CF samples 1985\n",
      "{'Accuracy': 0.8594658910629297, 'F1-Macro': 0.6216416510083019, 'F1-Weighted': 0.8732089224372187, 'F1_Class 0': 0.9164458576223281, 'F1_Class 1': 0.1705989110707804}\n",
      "Test size 0.9\n",
      "> Train samples 945\n",
      "{'Accuracy': 0.8393465742155365, 'F1-Macro': 0.5757280526113248, 'F1-Weighted': 0.8528704755393723, 'F1_Class 0': 0.9041202585871174, 'F1_Class 1': 0.08881578947368421}\n",
      "> Total Tweets used to generate counterfactuals 140\n",
      "> Total counterfactuals added 140\n",
      "> Counterfactual size 42 at rate 0.3\n",
      "> Train with CF samples 987\n",
      "{'Accuracy': 0.8402867552003761, 'F1-Macro': 0.5764198817097829, 'F1-Weighted': 0.8536775950948454, 'F1_Class 0': 0.9048731122528414, 'F1_Class 1': 0.08910891089108912}\n",
      "Religion (10869, 4)\n",
      "Test size 0.1\n",
      "> Train samples 9782\n",
      "{'Accuracy': 0.8574057037718491, 'F1-Macro': 0.6261956442209635, 'F1-Weighted': 0.8693727872927159, 'F1_Class 0': 0.9179755671902269, 'F1_Class 1': 0.2531645569620253}\n",
      "> Total Tweets used to generate counterfactuals 1385\n",
      "> Total counterfactuals added 1385\n",
      "> Counterfactual size 416 at rate 0.3\n",
      "> Train with CF samples 10198\n",
      "{'Accuracy': 0.860165593376265, 'F1-Macro': 0.6373552159795164, 'F1-Weighted': 0.8715322719662276, 'F1_Class 0': 0.9191390343222804, 'F1_Class 1': 0.28205128205128205}\n",
      "Test size 0.2\n",
      "> Train samples 8695\n",
      "{'Accuracy': 0.8652253909843606, 'F1-Macro': 0.6185427433838799, 'F1-Weighted': 0.8754590836008812, 'F1_Class 0': 0.9268011527377522, 'F1_Class 1': 0.23703703703703705}\n",
      "> Total Tweets used to generate counterfactuals 1235\n",
      "> Total counterfactuals added 1235\n",
      "> Counterfactual size 370 at rate 0.3\n",
      "> Train with CF samples 9065\n",
      "{'Accuracy': 0.8675252989880404, 'F1-Macro': 0.6174827371037698, 'F1-Weighted': 0.8768211360946349, 'F1_Class 0': 0.9276278001148766, 'F1_Class 1': 0.2272727272727273}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 7608\n",
      "{'Accuracy': 0.8610855565777369, 'F1-Macro': 0.6276359065811118, 'F1-Weighted': 0.8738345873059803, 'F1_Class 0': 0.9212962962962963, 'F1_Class 1': 0.2531645569620253}\n",
      "> Total Tweets used to generate counterfactuals 1085\n",
      "> Total counterfactuals added 1085\n",
      "> Counterfactual size 326 at rate 0.3\n",
      "> Train with CF samples 7934\n",
      "{'Accuracy': 0.8623121741796995, 'F1-Macro': 0.6333266070703353, 'F1-Weighted': 0.8741196021360158, 'F1_Class 0': 0.9217123023524874, 'F1_Class 1': 0.2731277533039648}\n",
      "Test size 0.4\n",
      "> Train samples 6521\n",
      "{'Accuracy': 0.8624655013799448, 'F1-Macro': 0.6446968312707181, 'F1-Weighted': 0.8744975140328323, 'F1_Class 0': 0.922385028289569, 'F1_Class 1': 0.30914826498422715}\n",
      "> Total Tweets used to generate counterfactuals 938\n",
      "> Total counterfactuals added 938\n",
      "> Counterfactual size 281 at rate 0.3\n",
      "> Train with CF samples 6802\n",
      "{'Accuracy': 0.8629254829806807, 'F1-Macro': 0.6420977024802558, 'F1-Weighted': 0.8747666621738209, 'F1_Class 0': 0.9224750036226634, 'F1_Class 1': 0.2984126984126984}\n",
      "Test size 0.5\n",
      "> Train samples 5434\n",
      "{'Accuracy': 0.8579576816927323, 'F1-Macro': 0.636261984430354, 'F1-Weighted': 0.8708296632991582, 'F1_Class 0': 0.9179906542056075, 'F1_Class 1': 0.28497409326424866}\n",
      "> Total Tweets used to generate counterfactuals 777\n",
      "> Total counterfactuals added 777\n",
      "> Counterfactual size 233 at rate 0.3\n",
      "> Train with CF samples 5667\n",
      "{'Accuracy': 0.8677092916283349, 'F1-Macro': 0.6397814220803165, 'F1-Weighted': 0.878246794147014, 'F1_Class 0': 0.9255011006835825, 'F1_Class 1': 0.2793296089385475}\n",
      "Test size 0.6\n",
      "> Train samples 4347\n",
      "{'Accuracy': 0.8455995093529592, 'F1-Macro': 0.6193199092268018, 'F1-Weighted': 0.8601509836854436, 'F1_Class 0': 0.9103879605198867, 'F1_Class 1': 0.2703862660944206}\n",
      "> Total Tweets used to generate counterfactuals 632\n",
      "> Total counterfactuals added 632\n",
      "> Counterfactual size 190 at rate 0.3\n",
      "> Train with CF samples 4537\n",
      "{'Accuracy': 0.8618521925789635, 'F1-Macro': 0.6328678720139358, 'F1-Weighted': 0.8723753745403634, 'F1_Class 0': 0.9215913480108151, 'F1_Class 1': 0.2822384428223844}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3260\n",
      "{'Accuracy': 0.8426862925482981, 'F1-Macro': 0.6002432802325842, 'F1-Weighted': 0.856500327160518, 'F1_Class 0': 0.9089852184022587, 'F1_Class 1': 0.2318271119842829}\n",
      "> Total Tweets used to generate counterfactuals 504\n",
      "> Total counterfactuals added 504\n",
      "> Counterfactual size 151 at rate 0.3\n",
      "> Train with CF samples 3411\n",
      "{'Accuracy': 0.8567485871993692, 'F1-Macro': 0.6123261751612564, 'F1-Weighted': 0.8681731002333422, 'F1_Class 0': 0.9189544632582607, 'F1_Class 1': 0.23647294589178358}\n",
      "Test size 0.8\n",
      "> Train samples 2173\n",
      "{'Accuracy': 0.7930082796688133, 'F1-Macro': 0.5608615533110248, 'F1-Weighted': 0.8199470489839954, 'F1_Class 0': 0.8771587325424237, 'F1_Class 1': 0.20567375886524825}\n",
      "> Total Tweets used to generate counterfactuals 338\n",
      "> Total counterfactuals added 338\n",
      "> Counterfactual size 101 at rate 0.3\n",
      "> Train with CF samples 2274\n",
      "{'Accuracy': 0.8185372585096596, 'F1-Macro': 0.5786459539527057, 'F1-Weighted': 0.8407721448503449, 'F1_Class 0': 0.8948493110308747, 'F1_Class 1': 0.2007434944237918}\n",
      "Test size 0.9\n",
      "> Train samples 1086\n",
      "{'Accuracy': 0.7091894102013697, 'F1-Macro': 0.48839982500805296, 'F1-Weighted': 0.7495415692985966, 'F1_Class 0': 0.8157223796033993, 'F1_Class 1': 0.16928657799274485}\n",
      "> Total Tweets used to generate counterfactuals 171\n",
      "> Total counterfactuals added 171\n",
      "> Counterfactual size 51 at rate 0.3\n",
      "> Train with CF samples 1137\n",
      "{'Accuracy': 0.7203311867525299, 'F1-Macro': 0.4899858300168618, 'F1-Weighted': 0.7587344573459833, 'F1_Class 0': 0.8256572029442693, 'F1_Class 1': 0.1559074299634592}\n",
      "Race (12013, 4)\n",
      "Test size 0.1\n",
      "> Train samples 10811\n",
      "{'Accuracy': 0.870216306156406, 'F1-Macro': 0.618873198463762, 'F1-Weighted': 0.8856693461146754, 'F1_Class 0': 0.9297458893871451, 'F1_Class 1': 0.29333333333333333}\n",
      "> Total Tweets used to generate counterfactuals 982\n",
      "> Total counterfactuals added 982\n",
      "> Counterfactual size 295 at rate 0.3\n",
      "> Train with CF samples 11106\n",
      "{'Accuracy': 0.8685524126455907, 'F1-Macro': 0.6114530247964026, 'F1-Weighted': 0.88447234694892, 'F1_Class 0': 0.9303482587064678, 'F1_Class 1': 0.28571428571428575}\n",
      "Test size 0.2\n",
      "> Train samples 9610\n",
      "{'Accuracy': 0.8709945900957137, 'F1-Macro': 0.614247860600243, 'F1-Weighted': 0.8864814357660515, 'F1_Class 0': 0.9314257523433646, 'F1_Class 1': 0.30666666666666664}\n",
      "> Total Tweets used to generate counterfactuals 882\n",
      "> Total counterfactuals added 882\n",
      "> Counterfactual size 265 at rate 0.3\n",
      "> Train with CF samples 9875\n",
      "{'Accuracy': 0.873491468997087, 'F1-Macro': 0.616921091542176, 'F1-Weighted': 0.8884110764525189, 'F1_Class 0': 0.9334975369458128, 'F1_Class 1': 0.3129251700680272}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 8409\n",
      "{'Accuracy': 0.8773584905660378, 'F1-Macro': 0.6328071216541366, 'F1-Weighted': 0.8903403624595198, 'F1_Class 0': 0.9341435375266876, 'F1_Class 1': 0.3444976076555024}\n",
      "> Total Tweets used to generate counterfactuals 770\n",
      "> Total counterfactuals added 770\n",
      "> Counterfactual size 231 at rate 0.3\n",
      "> Train with CF samples 8640\n",
      "{'Accuracy': 0.8809655937846836, 'F1-Macro': 0.6367499464226337, 'F1-Weighted': 0.8931593371708854, 'F1_Class 0': 0.9365885630018024, 'F1_Class 1': 0.34782608695652173}\n",
      "Test size 0.4\n",
      "> Train samples 7207\n",
      "{'Accuracy': 0.8684977111943404, 'F1-Macro': 0.6219825334814746, 'F1-Weighted': 0.8827820114949418, 'F1_Class 0': 0.9292353451480977, 'F1_Class 1': 0.3333333333333333}\n",
      "> Total Tweets used to generate counterfactuals 651\n",
      "> Total counterfactuals added 651\n",
      "> Counterfactual size 195 at rate 0.3\n",
      "> Train with CF samples 7402\n",
      "{'Accuracy': 0.8701622971285893, 'F1-Macro': 0.6236388948899456, 'F1-Weighted': 0.8840972635718657, 'F1_Class 0': 0.930295901943791, 'F1_Class 1': 0.3333333333333333}\n",
      "Test size 0.5\n",
      "> Train samples 6006\n",
      "{'Accuracy': 0.8686532378891294, 'F1-Macro': 0.6210798891916669, 'F1-Weighted': 0.8826482891327333, 'F1_Class 0': 0.9297200714711138, 'F1_Class 1': 0.33149171270718236}\n",
      "> Total Tweets used to generate counterfactuals 542\n",
      "> Total counterfactuals added 542\n",
      "> Counterfactual size 163 at rate 0.3\n",
      "> Train with CF samples 6169\n",
      "{'Accuracy': 0.872482104211753, 'F1-Macro': 0.6260494189200937, 'F1-Weighted': 0.8852868530134498, 'F1_Class 0': 0.9320273078064708, 'F1_Class 1': 0.33994334277620397}\n",
      "Test size 0.6\n",
      "> Train samples 4805\n",
      "{'Accuracy': 0.8666759156492786, 'F1-Macro': 0.6216797791945224, 'F1-Weighted': 0.880474514208294, 'F1_Class 0': 0.9290205162144276, 'F1_Class 1': 0.34684684684684686}\n",
      "> Total Tweets used to generate counterfactuals 417\n",
      "> Total counterfactuals added 417\n",
      "> Counterfactual size 125 at rate 0.3\n",
      "> Train with CF samples 4930\n",
      "{'Accuracy': 0.8733351831298557, 'F1-Macro': 0.6290399908494472, 'F1-Weighted': 0.8853430437000683, 'F1_Class 0': 0.9327065809005444, 'F1_Class 1': 0.34951456310679613}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3603\n",
      "{'Accuracy': 0.867538644470868, 'F1-Macro': 0.6128729391275839, 'F1-Weighted': 0.8814022434658931, 'F1_Class 0': 0.9303967245517436, 'F1_Class 1': 0.3256704980842912}\n",
      "> Total Tweets used to generate counterfactuals 326\n",
      "> Total counterfactuals added 326\n",
      "> Counterfactual size 98 at rate 0.3\n",
      "> Train with CF samples 3701\n",
      "{'Accuracy': 0.8707491082045185, 'F1-Macro': 0.6162021806465781, 'F1-Weighted': 0.8839879053715066, 'F1_Class 0': 0.932459108855048, 'F1_Class 1': 0.32558139534883723}\n",
      "Test size 0.8\n",
      "> Train samples 2402\n",
      "{'Accuracy': 0.8504838206222037, 'F1-Macro': 0.5827315029316646, 'F1-Weighted': 0.867525616951619, 'F1_Class 0': 0.9215114475398647, 'F1_Class 1': 0.2943854324734447}\n",
      "> Total Tweets used to generate counterfactuals 205\n",
      "> Total counterfactuals added 205\n",
      "> Counterfactual size 62 at rate 0.3\n",
      "> Train with CF samples 2464\n",
      "{'Accuracy': 0.8564145250234106, 'F1-Macro': 0.5855281394339881, 'F1-Weighted': 0.8720332150227195, 'F1_Class 0': 0.9258710155670867, 'F1_Class 1': 0.29046898638426627}\n",
      "Test size 0.9\n",
      "> Train samples 1201\n",
      "{'Accuracy': 0.8421198668146503, 'F1-Macro': 0.5487900096825509, 'F1-Weighted': 0.8597452602796786, 'F1_Class 0': 0.9153459605720912, 'F1_Class 1': 0.20086083213773315}\n",
      "> Total Tweets used to generate counterfactuals 104\n",
      "> Total counterfactuals added 104\n",
      "> Counterfactual size 31 at rate 0.3\n",
      "> Train with CF samples 1232\n",
      "{'Accuracy': 0.8438771735109138, 'F1-Macro': 0.5493133828658847, 'F1-Weighted': 0.8608594072922828, 'F1_Class 0': 0.9162762497933087, 'F1_Class 1': 0.1977077363896848}\n",
      "Politics (11018, 4)\n",
      "Test size 0.1\n",
      "> Train samples 9916\n",
      "{'Accuracy': 0.8793103448275862, 'F1-Macro': 0.6834123590198512, 'F1-Weighted': 0.886508668970203, 'F1_Class 0': 0.9376927822331893, 'F1_Class 1': 0.3294117647058824}\n",
      "> Total Tweets used to generate counterfactuals 1838\n",
      "> Total counterfactuals added 1838\n",
      "> Counterfactual size 551 at rate 0.3\n",
      "> Train with CF samples 10467\n",
      "{'Accuracy': 0.882940108892922, 'F1-Macro': 0.6849598812015998, 'F1-Weighted': 0.8904087766284136, 'F1_Class 0': 0.9391518131530424, 'F1_Class 1': 0.3181818181818182}\n",
      "Test size 0.2\n",
      "> Train samples 8814\n",
      "{'Accuracy': 0.882940108892922, 'F1-Macro': 0.7014726665194663, 'F1-Weighted': 0.891219142173081, 'F1_Class 0': 0.9412849677221028, 'F1_Class 1': 0.3804347826086957}\n",
      "> Total Tweets used to generate counterfactuals 1636\n",
      "> Total counterfactuals added 1636\n",
      "> Counterfactual size 491 at rate 0.3\n",
      "> Train with CF samples 9305\n",
      "{'Accuracy': 0.8847549909255898, 'F1-Macro': 0.6884893883601039, 'F1-Weighted': 0.8927543829491528, 'F1_Class 0': 0.9433731251913071, 'F1_Class 1': 0.3333333333333333}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 7712\n",
      "{'Accuracy': 0.8793103448275862, 'F1-Macro': 0.6958884651890394, 'F1-Weighted': 0.887122695124974, 'F1_Class 0': 0.9371146732429101, 'F1_Class 1': 0.36764705882352944}\n",
      "> Total Tweets used to generate counterfactuals 1400\n",
      "> Total counterfactuals added 1400\n",
      "> Counterfactual size 420 at rate 0.3\n",
      "> Train with CF samples 8132\n",
      "{'Accuracy': 0.8850574712643678, 'F1-Macro': 0.6968029556069424, 'F1-Weighted': 0.8917276186746977, 'F1_Class 0': 0.9406224406224407, 'F1_Class 1': 0.35658914728682173}\n",
      "Test size 0.4\n",
      "> Train samples 6610\n",
      "{'Accuracy': 0.8768148820326679, 'F1-Macro': 0.6865702163753657, 'F1-Weighted': 0.885881854002294, 'F1_Class 0': 0.935341548760079, 'F1_Class 1': 0.35195530726256985}\n",
      "> Total Tweets used to generate counterfactuals 1219\n",
      "> Total counterfactuals added 1219\n",
      "> Counterfactual size 366 at rate 0.3\n",
      "> Train with CF samples 6976\n",
      "{'Accuracy': 0.8840744101633394, 'F1-Macro': 0.6918377126621685, 'F1-Weighted': 0.8924359127381429, 'F1_Class 0': 0.9402668283808369, 'F1_Class 1': 0.3495702005730659}\n",
      "Test size 0.5\n",
      "> Train samples 5509\n",
      "{'Accuracy': 0.87021237974224, 'F1-Macro': 0.6714236641018086, 'F1-Weighted': 0.8797834332960187, 'F1_Class 0': 0.9312195121951221, 'F1_Class 1': 0.3212669683257918}\n",
      "> Total Tweets used to generate counterfactuals 1014\n",
      "> Total counterfactuals added 1014\n",
      "> Counterfactual size 304 at rate 0.3\n",
      "> Train with CF samples 5813\n",
      "{'Accuracy': 0.8783808313668542, 'F1-Macro': 0.6843475802481193, 'F1-Weighted': 0.8877658815537015, 'F1_Class 0': 0.9357351509250244, 'F1_Class 1': 0.336322869955157}\n",
      "Test size 0.6\n",
      "> Train samples 4407\n",
      "{'Accuracy': 0.8694599909242172, 'F1-Macro': 0.6631700123437039, 'F1-Weighted': 0.8809865086527389, 'F1_Class 0': 0.9322603646735256, 'F1_Class 1': 0.29136690647482016}\n",
      "> Total Tweets used to generate counterfactuals 818\n",
      "> Total counterfactuals added 818\n",
      "> Counterfactual size 245 at rate 0.3\n",
      "> Train with CF samples 4652\n",
      "{'Accuracy': 0.8700650431099682, 'F1-Macro': 0.6558545419542229, 'F1-Weighted': 0.8814826722654058, 'F1_Class 0': 0.9332113449222325, 'F1_Class 1': 0.26691042047531993}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3305\n",
      "{'Accuracy': 0.8637365486840399, 'F1-Macro': 0.6444434011561341, 'F1-Weighted': 0.8762614204808699, 'F1_Class 0': 0.9267610557594826, 'F1_Class 1': 0.2369230769230769}\n",
      "> Total Tweets used to generate counterfactuals 601\n",
      "> Total counterfactuals added 601\n",
      "> Counterfactual size 180 at rate 0.3\n",
      "> Train with CF samples 3485\n",
      "{'Accuracy': 0.868922598210813, 'F1-Macro': 0.6517351185308412, 'F1-Weighted': 0.8808811469806027, 'F1_Class 0': 0.9288082359099633, 'F1_Class 1': 0.2433697347893916}\n",
      "Test size 0.8\n",
      "> Train samples 2203\n",
      "{'Accuracy': 0.8301758366420874, 'F1-Macro': 0.617033678673638, 'F1-Weighted': 0.8434540721975964, 'F1_Class 0': 0.9018367031949375, 'F1_Class 1': 0.2465753424657534}\n",
      "> Total Tweets used to generate counterfactuals 409\n",
      "> Total counterfactuals added 409\n",
      "> Counterfactual size 123 at rate 0.3\n",
      "> Train with CF samples 2326\n",
      "{'Accuracy': 0.8372093023255814, 'F1-Macro': 0.6225609225374618, 'F1-Weighted': 0.8490350146638539, 'F1_Class 0': 0.9068361019673887, 'F1_Class 1': 0.25034770514603616}\n",
      "Test size 0.9\n",
      "> Train samples 1101\n",
      "{'Accuracy': 0.77442775032772, 'F1-Macro': 0.5556223911513741, 'F1-Weighted': 0.800285390542726, 'F1_Class 0': 0.8690560180612389, 'F1_Class 1': 0.16934046345811052}\n",
      "> Total Tweets used to generate counterfactuals 195\n",
      "> Total counterfactuals added 195\n",
      "> Counterfactual size 58 at rate 0.3\n",
      "> Train with CF samples 1159\n",
      "{'Accuracy': 0.7886457598063931, 'F1-Macro': 0.563295096139259, 'F1-Weighted': 0.8112010829977628, 'F1_Class 0': 0.8784302772152782, 'F1_Class 1': 0.16506717850287908}\n",
      "Sports (12306, 4)\n",
      "Test size 0.1\n",
      "> Train samples 11075\n",
      "{'Accuracy': 0.925264012997563, 'F1-Macro': 0.732492163770202, 'F1-Weighted': 0.9310597782589415, 'F1_Class 0': 0.9645244215938303, 'F1_Class 1': 0.3764705882352941}\n",
      "> Total Tweets used to generate counterfactuals 1674\n",
      "> Total counterfactuals added 1674\n",
      "> Counterfactual size 502 at rate 0.3\n",
      "> Train with CF samples 11577\n",
      "{'Accuracy': 0.9285134037367994, 'F1-Macro': 0.7373959188437963, 'F1-Weighted': 0.9339715614414001, 'F1_Class 0': 0.9661190965092401, 'F1_Class 1': 0.38095238095238093}\n",
      "Test size 0.2\n",
      "> Train samples 9844\n",
      "{'Accuracy': 0.9224207961007311, 'F1-Macro': 0.7200535663578199, 'F1-Weighted': 0.928674975076492, 'F1_Class 0': 0.9653388515261253, 'F1_Class 1': 0.3536585365853658}\n",
      "> Total Tweets used to generate counterfactuals 1467\n",
      "> Total counterfactuals added 1467\n",
      "> Counterfactual size 440 at rate 0.3\n",
      "> Train with CF samples 10284\n",
      "{'Accuracy': 0.9240454914703493, 'F1-Macro': 0.7207077367922518, 'F1-Weighted': 0.9309304590479951, 'F1_Class 0': 0.9677086024283131, 'F1_Class 1': 0.3508771929824561}\n",
      "Test size 0.30000000000000004\n",
      "> Train samples 8614\n",
      "{'Accuracy': 0.9209100758396533, 'F1-Macro': 0.7124487838660952, 'F1-Weighted': 0.9287846436019896, 'F1_Class 0': 0.9643162028342155, 'F1_Class 1': 0.3373493975903614}\n",
      "> Total Tweets used to generate counterfactuals 1302\n",
      "> Total counterfactuals added 1302\n",
      "> Counterfactual size 391 at rate 0.3\n",
      "> Train with CF samples 9005\n",
      "{'Accuracy': 0.9233477789815818, 'F1-Macro': 0.7151993276284955, 'F1-Weighted': 0.9311453080027066, 'F1_Class 0': 0.9657289002557544, 'F1_Class 1': 0.3373493975903614}\n",
      "Test size 0.4\n",
      "> Train samples 7383\n",
      "{'Accuracy': 0.9213893967093236, 'F1-Macro': 0.7065639586932302, 'F1-Weighted': 0.9312704731832231, 'F1_Class 0': 0.9635596471039509, 'F1_Class 1': 0.30678466076696165}\n",
      "> Total Tweets used to generate counterfactuals 1124\n",
      "> Total counterfactuals added 1124\n",
      "> Counterfactual size 337 at rate 0.3\n",
      "> Train with CF samples 7720\n",
      "{'Accuracy': 0.9264676010562665, 'F1-Macro': 0.7156230931861683, 'F1-Weighted': 0.9361010216955583, 'F1_Class 0': 0.9667943805874841, 'F1_Class 1': 0.3195266272189349}\n",
      "Test size 0.5\n",
      "> Train samples 6153\n",
      "{'Accuracy': 0.9241020640338047, 'F1-Macro': 0.7134369407122216, 'F1-Weighted': 0.934704571653032, 'F1_Class 0': 0.9648621041879469, 'F1_Class 1': 0.32211538461538464}\n",
      "> Total Tweets used to generate counterfactuals 963\n",
      "> Total counterfactuals added 963\n",
      "> Counterfactual size 289 at rate 0.3\n",
      "> Train with CF samples 6442\n",
      "{'Accuracy': 0.92442710872745, 'F1-Macro': 0.713492709663011, 'F1-Weighted': 0.9351221906097985, 'F1_Class 0': 0.9650806616295692, 'F1_Class 1': 0.32057416267942584}\n",
      "Test size 0.6\n",
      "> Train samples 4922\n",
      "{'Accuracy': 0.9241603466955579, 'F1-Macro': 0.7074916406593327, 'F1-Weighted': 0.935056356215326, 'F1_Class 0': 0.9665079904794288, 'F1_Class 1': 0.3073852295409182}\n",
      "> Total Tweets used to generate counterfactuals 785\n",
      "> Total counterfactuals added 785\n",
      "> Counterfactual size 236 at rate 0.3\n",
      "> Train with CF samples 5158\n",
      "{'Accuracy': 0.9289003250270856, 'F1-Macro': 0.7152495105973582, 'F1-Weighted': 0.9382619195334749, 'F1_Class 0': 0.968972533062055, 'F1_Class 1': 0.3227176220806794}\n",
      "Test size 0.7000000000000001\n",
      "> Train samples 3691\n",
      "{'Accuracy': 0.9164248403946604, 'F1-Macro': 0.700985604595056, 'F1-Weighted': 0.927839920258637, 'F1_Class 0': 0.9629305950040055, 'F1_Class 1': 0.31612903225806455}\n",
      "> Total Tweets used to generate counterfactuals 596\n",
      "> Total counterfactuals added 596\n",
      "> Counterfactual size 179 at rate 0.3\n",
      "> Train with CF samples 3870\n",
      "{'Accuracy': 0.9202553685432385, 'F1-Macro': 0.7052017414185644, 'F1-Weighted': 0.9318313569011644, 'F1_Class 0': 0.9650410640308161, 'F1_Class 1': 0.31360000000000005}\n",
      "Test size 0.8\n",
      "> Train samples 2461\n",
      "{'Accuracy': 0.8800406297613002, 'F1-Macro': 0.6457512640723537, 'F1-Weighted': 0.8931928170416059, 'F1_Class 0': 0.9422780913288866, 'F1_Class 1': 0.26288659793814434}\n",
      "> Total Tweets used to generate counterfactuals 401\n",
      "> Total counterfactuals added 401\n",
      "> Counterfactual size 120 at rate 0.3\n",
      "> Train with CF samples 2581\n",
      "{'Accuracy': 0.9027932960893855, 'F1-Macro': 0.6744157144287998, 'F1-Weighted': 0.9140708107508054, 'F1_Class 0': 0.9550576022281302, 'F1_Class 1': 0.27851458885941643}\n",
      "Test size 0.9\n",
      "> Train samples 1230\n",
      "{'Accuracy': 0.8451607078367642, 'F1-Macro': 0.5904232676259887, 'F1-Weighted': 0.8654700451813095, 'F1_Class 0': 0.927579650861324, 'F1_Class 1': 0.19056261343012706}\n",
      "> Total Tweets used to generate counterfactuals 207\n",
      "> Total counterfactuals added 207\n",
      "> Counterfactual size 62 at rate 0.3\n",
      "> Train with CF samples 1292\n",
      "{'Accuracy': 0.874593716143012, 'F1-Macro': 0.6209711165394521, 'F1-Weighted': 0.885681116487283, 'F1_Class 0': 0.9444068561118629, 'F1_Class 1': 0.23214285714285715}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "for d in domains:\n",
    "    sel_df = df[df['Domain'] == d]\n",
    "    print(d, sel_df.shape)\n",
    "    X, y = sel_df['Tweet'], sel_df['Label'].astype(int)\n",
    "    # CHANGE --> solver='liblinear' added for l1, otherwise won't work\n",
    "    # CHANGE --> max_iter=10000 added for l2, otherwsie ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "    davidson_pipeline = Pipeline([('sel-lg-l1', SelectFromModel(LogisticRegression(class_weight='balanced',penalty=\"l1\",C=0.01, solver='liblinear'))),\n",
    "                                  ('lg-l2',LogisticRegression(class_weight='balanced',penalty='l2',C=0.01,  max_iter=10000))])\n",
    "\n",
    "    res_dav_lst = run_experiment(davidson_pipeline, test_size_list=test_size_list, cf_size_prop_to_data=cf_size_prop_to_data)\n",
    "    json.dump(res_dav_lst, open('out/davidson-pipline-lshd22-' + d + '.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f3406da-ca7c-4e84-97da-f8ec0f4cd211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0.3\n"
     ]
    }
   ],
   "source": [
    "print('done', cf_size_prop_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e292df-9624-4a45-9cdc-fdc418a6b774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "# patience counterfactual , fairness -> terms  (FAIR coference -> Followup)\n",
    "# ACL, workshop -> Extension Jorunal (new metric, bias of chatgpt) -->\n",
    "# Easy workshop at good conference.\n",
    "# Focus on the story, we dont tools data augmentation and generate counterfactual, and we show on application hatespeech\n",
    "# Senario of InEire: Internet Research, WWW, Policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfba6b-56ba-463b-9df1-eea3dfb20bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 > 0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
